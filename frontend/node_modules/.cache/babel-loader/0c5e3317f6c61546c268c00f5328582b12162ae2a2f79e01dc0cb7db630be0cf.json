{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\nvar lexer_1 = require(\"./lexer\");\nvar noop_1 = __importDefault(require(\"lodash/noop\"));\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\nvar last_1 = __importDefault(require(\"lodash/last\"));\nvar reject_1 = __importDefault(require(\"lodash/reject\"));\nvar map_1 = __importDefault(require(\"lodash/map\"));\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\nvar keys_1 = __importDefault(require(\"lodash/keys\"));\nvar isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\nvar identity_1 = __importDefault(require(\"lodash/identity\"));\nvar assign_1 = __importDefault(require(\"lodash/assign\"));\nvar reduce_1 = __importDefault(require(\"lodash/reduce\"));\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\nvar utils_1 = require(\"@chevrotain/utils\");\nvar tokens_1 = require(\"./tokens\");\nvar lexer_errors_public_1 = require(\"./lexer_errors_public\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\nvar DEFAULT_LEXER_CONFIG = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nvar Lexer = /** @class */function () {\n  function Lexer(lexerDefinition, config) {\n    if (config === void 0) {\n      config = DEFAULT_LEXER_CONFIG;\n    }\n    var _this = this;\n    this.lexerDefinition = lexerDefinition;\n    this.lexerDefinitionErrors = [];\n    this.lexerDefinitionWarning = [];\n    this.patternIdxToConfig = {};\n    this.charCodeToPatternIdxToConfig = {};\n    this.modes = [];\n    this.emptyGroups = {};\n    this.trackStartLines = true;\n    this.trackEndLines = true;\n    this.hasCustom = false;\n    this.canModeBeOptimized = {};\n    // Duplicated from the parser's perf trace trait to allow future extraction\n    // of the lexer to a separate package.\n    this.TRACE_INIT = function (phaseDesc, phaseImpl) {\n      // No need to optimize this using NOOP pattern because\n      // It is not called in a hot spot...\n      if (_this.traceInitPerf === true) {\n        _this.traceInitIndent++;\n        var indent = new Array(_this.traceInitIndent + 1).join(\"\\t\");\n        if (_this.traceInitIndent < _this.traceInitMaxIdent) {\n          console.log(\"\".concat(indent, \"--> <\").concat(phaseDesc, \">\"));\n        }\n        var _a = (0, utils_1.timer)(phaseImpl),\n          time = _a.time,\n          value = _a.value;\n        /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n        var traceMethod = time > 10 ? console.warn : console.log;\n        if (_this.traceInitIndent < _this.traceInitMaxIdent) {\n          traceMethod(\"\".concat(indent, \"<-- <\").concat(phaseDesc, \"> time: \").concat(time, \"ms\"));\n        }\n        _this.traceInitIndent--;\n        return value;\n      } else {\n        return phaseImpl();\n      }\n    };\n    if (typeof config === \"boolean\") {\n      throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" + \"a boolean 2nd argument is no longer supported\");\n    }\n    // todo: defaults func?\n    this.config = (0, assign_1.default)({}, DEFAULT_LEXER_CONFIG, config);\n    var traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n    this.TRACE_INIT(\"Lexer Constructor\", function () {\n      var actualDefinition;\n      var hasOnlySingleMode = true;\n      _this.TRACE_INIT(\"Lexer Config handling\", function () {\n        if (_this.config.lineTerminatorsPattern === DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          _this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\n        } else {\n          if (_this.config.lineTerminatorCharacters === DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n            throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n          }\n        }\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n        }\n        _this.trackStartLines = /full|onlyStart/i.test(_this.config.positionTracking);\n        _this.trackEndLines = /full/i.test(_this.config.positionTracking);\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if ((0, isArray_1.default)(lexerDefinition)) {\n          actualDefinition = {\n            modes: {\n              defaultMode: (0, clone_1.default)(lexerDefinition)\n            },\n            defaultMode: lexer_1.DEFAULT_MODE\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = (0, clone_1.default)(lexerDefinition);\n        }\n      });\n      if (_this.config.skipValidations === false) {\n        _this.TRACE_INIT(\"performRuntimeChecks\", function () {\n          _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat((0, lexer_1.performRuntimeChecks)(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n        });\n        _this.TRACE_INIT(\"performWarningRuntimeChecks\", function () {\n          _this.lexerDefinitionWarning = _this.lexerDefinitionWarning.concat((0, lexer_1.performWarningRuntimeChecks)(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n        });\n      }\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {};\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      (0, forEach_1.default)(actualDefinition.modes, function (currModeValue, currModeName) {\n        actualDefinition.modes[currModeName] = (0, reject_1.default)(currModeValue, function (currTokType) {\n          return (0, isUndefined_1.default)(currTokType);\n        });\n      });\n      var allModeNames = (0, keys_1.default)(actualDefinition.modes);\n      (0, forEach_1.default)(actualDefinition.modes, function (currModDef, currModName) {\n        _this.TRACE_INIT(\"Mode: <\".concat(currModName, \"> processing\"), function () {\n          _this.modes.push(currModName);\n          if (_this.config.skipValidations === false) {\n            _this.TRACE_INIT(\"validatePatterns\", function () {\n              _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat((0, lexer_1.validatePatterns)(currModDef, allModeNames));\n            });\n          }\n          // If definition errors were encountered, the analysis phase may fail unexpectedly/\n          // Considering a lexer with definition errors may never be used, there is no point\n          // to performing the analysis anyhow...\n          if ((0, isEmpty_1.default)(_this.lexerDefinitionErrors)) {\n            (0, tokens_1.augmentTokenTypes)(currModDef);\n            var currAnalyzeResult_1;\n            _this.TRACE_INIT(\"analyzeTokenTypes\", function () {\n              currAnalyzeResult_1 = (0, lexer_1.analyzeTokenTypes)(currModDef, {\n                lineTerminatorCharacters: _this.config.lineTerminatorCharacters,\n                positionTracking: config.positionTracking,\n                ensureOptimizations: config.ensureOptimizations,\n                safeMode: config.safeMode,\n                tracer: _this.TRACE_INIT\n              });\n            });\n            _this.patternIdxToConfig[currModName] = currAnalyzeResult_1.patternIdxToConfig;\n            _this.charCodeToPatternIdxToConfig[currModName] = currAnalyzeResult_1.charCodeToPatternIdxToConfig;\n            _this.emptyGroups = (0, assign_1.default)({}, _this.emptyGroups, currAnalyzeResult_1.emptyGroups);\n            _this.hasCustom = currAnalyzeResult_1.hasCustom || _this.hasCustom;\n            _this.canModeBeOptimized[currModName] = currAnalyzeResult_1.canBeOptimized;\n          }\n        });\n      });\n      _this.defaultMode = actualDefinition.defaultMode;\n      if (!(0, isEmpty_1.default)(_this.lexerDefinitionErrors) && !_this.config.deferDefinitionErrorsHandling) {\n        var allErrMessages = (0, map_1.default)(_this.lexerDefinitionErrors, function (error) {\n          return error.message;\n        });\n        var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n        throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n      }\n      // Only print warning if there are no errors, This will avoid pl\n      (0, forEach_1.default)(_this.lexerDefinitionWarning, function (warningDescriptor) {\n        (0, utils_1.PRINT_WARNING)(warningDescriptor.message);\n      });\n      _this.TRACE_INIT(\"Choosing sub-methods implementations\", function () {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (lexer_1.SUPPORT_STICKY) {\n          _this.chopInput = identity_1.default;\n          _this.match = _this.matchWithTest;\n        } else {\n          _this.updateLastIndex = noop_1.default;\n          _this.match = _this.matchWithExec;\n        }\n        if (hasOnlySingleMode) {\n          _this.handleModes = noop_1.default;\n        }\n        if (_this.trackStartLines === false) {\n          _this.computeNewColumn = identity_1.default;\n        }\n        if (_this.trackEndLines === false) {\n          _this.updateTokenEndLineColumnLocation = noop_1.default;\n        }\n        if (/full/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createFullToken;\n        } else if (/onlyStart/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createOffsetOnlyToken;\n        } else {\n          throw Error(\"Invalid <positionTracking> config option: \\\"\".concat(_this.config.positionTracking, \"\\\"\"));\n        }\n        if (_this.hasCustom) {\n          _this.addToken = _this.addTokenUsingPush;\n          _this.handlePayload = _this.handlePayloadWithCustom;\n        } else {\n          _this.addToken = _this.addTokenUsingMemberAccess;\n          _this.handlePayload = _this.handlePayloadNoCustom;\n        }\n      });\n      _this.TRACE_INIT(\"Failed Optimization Warnings\", function () {\n        var unOptimizedModes = (0, reduce_1.default)(_this.canModeBeOptimized, function (cannotBeOptimized, canBeOptimized, modeName) {\n          if (canBeOptimized === false) {\n            cannotBeOptimized.push(modeName);\n          }\n          return cannotBeOptimized;\n        }, []);\n        if (config.ensureOptimizations && !(0, isEmpty_1.default)(unOptimizedModes)) {\n          throw Error(\"Lexer Modes: < \".concat(unOptimizedModes.join(\", \"), \" > cannot be optimized.\\n\") + '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' + \"\\t Or inspect the console log for details on how to resolve these issues.\");\n        }\n      });\n      _this.TRACE_INIT(\"clearRegExpParserCache\", function () {\n        (0, reg_exp_parser_1.clearRegExpParserCache)();\n      });\n      _this.TRACE_INIT(\"toFastProperties\", function () {\n        (0, utils_1.toFastProperties)(_this);\n      });\n    });\n  }\n  Lexer.prototype.tokenize = function (text, initialMode) {\n    if (initialMode === void 0) {\n      initialMode = this.defaultMode;\n    }\n    if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n      var allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, function (error) {\n        return error.message;\n      });\n      var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n      throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n    }\n    return this.tokenizeInternal(text, initialMode);\n  };\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  Lexer.prototype.tokenizeInternal = function (text, initialMode) {\n    var _this = this;\n    var i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n    var orgText = text;\n    var orgLength = orgText.length;\n    var offset = 0;\n    var matchedTokensIndex = 0;\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    var guessedNumberOfTokens = this.hasCustom ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n    : Math.floor(text.length / 10);\n    var matchedTokens = new Array(guessedNumberOfTokens);\n    var errors = [];\n    var line = this.trackStartLines ? 1 : undefined;\n    var column = this.trackStartLines ? 1 : undefined;\n    var groups = (0, lexer_1.cloneEmptyGroups)(this.emptyGroups);\n    var trackLines = this.trackStartLines;\n    var lineTerminatorPattern = this.config.lineTerminatorsPattern;\n    var currModePatternsLength = 0;\n    var patternIdxToConfig = [];\n    var currCharCodeToPatternIdxToConfig = [];\n    var modeStack = [];\n    var emptyArray = [];\n    Object.freeze(emptyArray);\n    var getPossiblePatterns;\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n    function getPossiblePatternsOptimized(charCode) {\n      var optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(charCode);\n      var possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n    var pop_mode = function (popToken) {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (modeStack.length === 1 &&\n      // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n      // So no error should occur.\n      popToken.tokenType.PUSH_MODE === undefined) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        var msg_1 = _this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg_1\n        });\n      } else {\n        modeStack.pop();\n        var newMode = (0, last_1.default)(modeStack);\n        patternIdxToConfig = _this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig = _this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        var modeCanBeOptimized = _this.canModeBeOptimized[newMode] && _this.config.safeMode === false;\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n    function push_mode(newMode) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n      currModePatternsLength = patternIdxToConfig.length;\n      var modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode);\n    var currConfig;\n    var recoveryEnabled = this.config.recoveryEnabled;\n    while (offset < orgLength) {\n      matchedImage = null;\n      var nextCharCode = orgText.charCodeAt(offset);\n      var chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      var chosenPatternsLength = chosenPatternIdxToConfig.length;\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        var currPattern = currConfig.pattern;\n        payload = null;\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        var singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = currPattern.exec(orgText, offset, matchedTokens, groups);\n          if (match !== null) {\n            matchedImage = match[0];\n            if (match.payload !== undefined) {\n              payload = match.payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern, offset);\n          matchedImage = this.match(currPattern, text, offset);\n        }\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            var longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              var longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              var longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (match.payload !== undefined) {\n                    altPayload = match.payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern, offset);\n                matchAltImage = this.match(longerAltPattern, text, offset);\n              }\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx;\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n          this.handlePayload(newToken, payload);\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column, imageLength);\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          var numOfLTsInMatch = 0;\n          var foundTerminator = void 0;\n          var lastLTEndOffset = void 0;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n          if (numOfLTsInMatch !== 0) {\n            line = line + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset;\n            this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        var errorStartOffset = offset;\n        var errorLine = line;\n        var errorColumn = column;\n        var foundResyncPoint = recoveryEnabled === false;\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            var currConfig_1 = patternIdxToConfig[j];\n            var currPattern = currConfig_1.pattern;\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            var singleCharCode = currConfig_1.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig_1.isCustom === true) {\n              foundResyncPoint = currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n            } else {\n              this.updateLastIndex(currPattern, offset);\n              foundResyncPoint = currPattern.exec(text) !== null;\n            }\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n        errLength = offset - errorStartOffset;\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        });\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors\n    };\n  };\n  Lexer.prototype.handleModes = function (config, pop_mode, push_mode, newToken) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      var pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  };\n  Lexer.prototype.chopInput = function (text, length) {\n    return text.substring(length);\n  };\n  Lexer.prototype.updateLastIndex = function (regExp, newLastIndex) {\n    regExp.lastIndex = newLastIndex;\n  };\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  Lexer.prototype.updateTokenEndLineColumnLocation = function (newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n    var lastCharIsLT, fixForEndingInLT;\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT;\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  };\n\n  Lexer.prototype.computeNewColumn = function (oldColumn, imageLength) {\n    return oldColumn + imageLength;\n  };\n  Lexer.prototype.createOffsetOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n  Lexer.prototype.createStartOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      startLine: startLine,\n      startColumn: startColumn,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n  Lexer.prototype.createFullToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine: startLine,\n      endLine: startLine,\n      startColumn: startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n  Lexer.prototype.addTokenUsingPush = function (tokenVector, index, tokenToAdd) {\n    tokenVector.push(tokenToAdd);\n    return index;\n  };\n  Lexer.prototype.addTokenUsingMemberAccess = function (tokenVector, index, tokenToAdd) {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  };\n  Lexer.prototype.handlePayloadNoCustom = function (token, payload) {};\n  Lexer.prototype.handlePayloadWithCustom = function (token, payload) {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  };\n  Lexer.prototype.matchWithTest = function (pattern, text, offset) {\n    var found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  };\n  Lexer.prototype.matchWithExec = function (pattern, text) {\n    var regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  };\n  Lexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" + \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n  Lexer.NA = /NOT_APPLICABLE/;\n  return Lexer;\n}();\nexports.Lexer = Lexer;","map":{"version":3,"mappings":";;;;;;;;;;;AAAA;AAaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAWA;AACA;AAQA,IAAYA,wBAmBX;AAnBD,WAAYA,wBAAwB;EAClCA,6FAAe;EACfA,6FAAe;EACfA,+FAAgB;EAChBA,6GAAuB;EACvBA,+GAAwB;EACxBA,+GAAwB;EACxBA,+GAAwB;EACxBA,yIAAqC;EACrCA,6IAAuC;EACvCA,mKAAkD;EAClDA,kJAAyC;EACzCA,gGAAgB;EAChBA,sGAAmB;EACnBA,wGAAoB;EACpBA,sGAAmB;EACnBA,sGAAmB;EACnBA,kGAAiB;EACjBA,8JAA+C;AACjD,CAAC,EAnBWA,wBAAwB,GAAxBC,gCAAwB,KAAxBA,gCAAwB;AAyBpC,IAAMC,oBAAoB,GAA2B;EACnDC,6BAA6B,EAAE,KAAK;EACpCC,gBAAgB,EAAE,MAAM;EACxBC,sBAAsB,EAAE,WAAW;EACnCC,wBAAwB,EAAE,CAAC,IAAI,EAAE,IAAI,CAAC;EACtCC,mBAAmB,EAAE,KAAK;EAC1BC,QAAQ,EAAE,KAAK;EACfC,oBAAoB,EAAEC,+CAAyB;EAC/CC,aAAa,EAAE,KAAK;EACpBC,eAAe,EAAE,KAAK;EACtBC,eAAe,EAAE;CAClB;AAEDC,MAAM,CAACC,MAAM,CAACb,oBAAoB,CAAC;AAEnC;EA4BE,eACYc,eAAwD,EAClEC,MAA2C;IAA3C;MAAAA,6BAA2C;IAAA;IAF7C;IACY,oBAAe,GAAfD,eAAe;IAvBpB,0BAAqB,GAA4B,EAAE;IACnD,2BAAsB,GAA4B,EAAE;IAEjD,uBAAkB,GAAqC,EAAE;IACzD,iCAA4B,GAElC,EAAE;IAEI,UAAK,GAAa,EAAE;IAEpB,gBAAW,GAAoC,EAAE;IAGnD,oBAAe,GAAY,IAAI;IAC/B,kBAAa,GAAY,IAAI;IAC7B,cAAS,GAAY,KAAK;IAC1B,uBAAkB,GAA4B,EAAE;IAo0BxD;IACA;IACA,eAAU,GAAG,UAAIE,SAAiB,EAAEC,SAAkB;MACpD;MACA;MACA,IAAIC,KAAI,CAACT,aAAa,KAAK,IAAI,EAAE;QAC/BS,KAAI,CAACC,eAAe,EAAE;QACtB,IAAMC,MAAM,GAAG,IAAIC,KAAK,CAACH,KAAI,CAACC,eAAe,GAAG,CAAC,CAAC,CAACG,IAAI,CAAC,IAAI,CAAC;QAC7D,IAAIJ,KAAI,CAACC,eAAe,GAAGD,KAAI,CAACK,iBAAiB,EAAE;UACjDC,OAAO,CAACC,GAAG,CAAC,UAAGL,MAAM,kBAAQJ,SAAS,MAAG,CAAC;;QAEtC,SAAkB,iBAAK,EAACC,SAAS,CAAC;UAAhCS,IAAI;UAAEC,KAAK,WAAqB;QACxC;QACA,IAAMC,WAAW,GAAGF,IAAI,GAAG,EAAE,GAAGF,OAAO,CAACK,IAAI,GAAGL,OAAO,CAACC,GAAG;QAC1D,IAAIP,KAAI,CAACC,eAAe,GAAGD,KAAI,CAACK,iBAAiB,EAAE;UACjDK,WAAW,CAAC,UAAGR,MAAM,kBAAQJ,SAAS,qBAAWU,IAAI,OAAI,CAAC;;QAE5DR,KAAI,CAACC,eAAe,EAAE;QACtB,OAAOQ,KAAK;OACb,MAAM;QACL,OAAOV,SAAS,EAAE;;IAEtB,CAAC;IAh1BC,IAAI,OAAOF,MAAM,KAAK,SAAS,EAAE;MAC/B,MAAMe,KAAK,CACT,+EAA+E,GAC7E,+CAA+C,CAClD;;IAGH;IACA,IAAI,CAACf,MAAM,GAAG,oBAAM,EAAC,EAAE,EAAEf,oBAAoB,EAAEe,MAAM,CAAQ;IAE7D,IAAMgB,YAAY,GAAG,IAAI,CAAChB,MAAM,CAACN,aAAa;IAC9C,IAAIsB,YAAY,KAAK,IAAI,EAAE;MACzB,IAAI,CAACR,iBAAiB,GAAGS,QAAQ;MACjC,IAAI,CAACvB,aAAa,GAAG,IAAI;KAC1B,MAAM,IAAI,OAAOsB,YAAY,KAAK,QAAQ,EAAE;MAC3C,IAAI,CAACR,iBAAiB,GAAGQ,YAAY;MACrC,IAAI,CAACtB,aAAa,GAAG,IAAI;;IAE3B,IAAI,CAACU,eAAe,GAAG,CAAC,CAAC;IAEzB,IAAI,CAACc,UAAU,CAAC,mBAAmB,EAAE;MACnC,IAAIC,gBAA4C;MAChD,IAAIC,iBAAiB,GAAG,IAAI;MAC5BjB,KAAI,CAACe,UAAU,CAAC,uBAAuB,EAAE;QACvC,IACEf,KAAI,CAACH,MAAM,CAACZ,sBAAsB,KAClCH,oBAAoB,CAACG,sBAAsB,EAC3C;UACA;UACAe,KAAI,CAACH,MAAM,CAACZ,sBAAsB,GAAGiC,qCAA6B;SACnE,MAAM;UACL,IACElB,KAAI,CAACH,MAAM,CAACX,wBAAwB,KACpCJ,oBAAoB,CAACI,wBAAwB,EAC7C;YACA,MAAM0B,KAAK,CACT,2EAA2E,GACzE,yGAAyG,CAC5G;;;QAIL,IAAIf,MAAM,CAACT,QAAQ,IAAIS,MAAM,CAACV,mBAAmB,EAAE;UACjD,MAAMyB,KAAK,CACT,oEAAoE,CACrE;;QAGHZ,KAAI,CAACmB,eAAe,GAAG,iBAAiB,CAACC,IAAI,CAC3CpB,KAAI,CAACH,MAAM,CAACb,gBAAgB,CAC7B;QACDgB,KAAI,CAACqB,aAAa,GAAG,OAAO,CAACD,IAAI,CAACpB,KAAI,CAACH,MAAM,CAACb,gBAAgB,CAAC;QAE/D;QACA,IAAI,qBAAO,EAACY,eAAe,CAAC,EAAE;UAC5BoB,gBAAgB,GAAG;YACjBM,KAAK,EAAE;cAAEC,WAAW,EAAE,mBAAK,EAAC3B,eAAe;YAAC,CAAE;YAC9C2B,WAAW,EAAEL;WACd;SACF,MAAM;UACL;UACAD,iBAAiB,GAAG,KAAK;UACzBD,gBAAgB,GAAG,mBAAK,EAA4BpB,eAAe,CAAC;;MAExE,CAAC,CAAC;MAEF,IAAII,KAAI,CAACH,MAAM,CAACL,eAAe,KAAK,KAAK,EAAE;QACzCQ,KAAI,CAACe,UAAU,CAAC,sBAAsB,EAAE;UACtCf,KAAI,CAACwB,qBAAqB,GAAGxB,KAAI,CAACwB,qBAAqB,CAACC,MAAM,CAC5D,gCAAoB,EAClBT,gBAAgB,EAChBhB,KAAI,CAACmB,eAAe,EACpBnB,KAAI,CAACH,MAAM,CAACX,wBAAwB,CACrC,CACF;QACH,CAAC,CAAC;QAEFc,KAAI,CAACe,UAAU,CAAC,6BAA6B,EAAE;UAC7Cf,KAAI,CAAC0B,sBAAsB,GAAG1B,KAAI,CAAC0B,sBAAsB,CAACD,MAAM,CAC9D,uCAA2B,EACzBT,gBAAgB,EAChBhB,KAAI,CAACmB,eAAe,EACpBnB,KAAI,CAACH,MAAM,CAACX,wBAAwB,CACrC,CACF;QACH,CAAC,CAAC;;MAGJ;MACA8B,gBAAgB,CAACM,KAAK,GAAGN,gBAAgB,CAACM,KAAK,GAC3CN,gBAAgB,CAACM,KAAK,GACtB,EAAE;MAEN;MACA;MACA,qBAAO,EAACN,gBAAgB,CAACM,KAAK,EAAE,UAACK,aAAa,EAAEC,YAAY;QAC1DZ,gBAAgB,CAACM,KAAK,CAACM,YAAY,CAAC,GAAG,oBAAM,EAC3CD,aAAa,EACb,UAACE,WAAW;UAAK,gCAAW,EAACA,WAAW,CAAC;QAAxB,CAAwB,CAC1C;MACH,CAAC,CAAC;MAEF,IAAMC,YAAY,GAAG,kBAAI,EAACd,gBAAgB,CAACM,KAAK,CAAC;MAEjD,qBAAO,EACLN,gBAAgB,CAACM,KAAK,EACtB,UAACS,UAAuB,EAAEC,WAAW;QACnChC,KAAI,CAACe,UAAU,CAAC,iBAAUiB,WAAW,iBAAc,EAAE;UACnDhC,KAAI,CAACsB,KAAK,CAACW,IAAI,CAACD,WAAW,CAAC;UAE5B,IAAIhC,KAAI,CAACH,MAAM,CAACL,eAAe,KAAK,KAAK,EAAE;YACzCQ,KAAI,CAACe,UAAU,CAAC,kBAAkB,EAAE;cAClCf,KAAI,CAACwB,qBAAqB,GAAGxB,KAAI,CAACwB,qBAAqB,CAACC,MAAM,CAC5D,4BAAgB,EAACM,UAAU,EAAED,YAAY,CAAC,CAC3C;YACH,CAAC,CAAC;;UAGJ;UACA;UACA;UACA,IAAI,qBAAO,EAAC9B,KAAI,CAACwB,qBAAqB,CAAC,EAAE;YACvC,8BAAiB,EAACO,UAAU,CAAC;YAE7B,IAAIG,mBAAkC;YACtClC,KAAI,CAACe,UAAU,CAAC,mBAAmB,EAAE;cACnCmB,mBAAiB,GAAG,6BAAiB,EAACH,UAAU,EAAE;gBAChD7C,wBAAwB,EACtBc,KAAI,CAACH,MAAM,CAACX,wBAAwB;gBACtCF,gBAAgB,EAAEa,MAAM,CAACb,gBAAgB;gBACzCG,mBAAmB,EAAEU,MAAM,CAACV,mBAAmB;gBAC/CC,QAAQ,EAAES,MAAM,CAACT,QAAQ;gBACzB+C,MAAM,EAAEnC,KAAI,CAACe;eACd,CAAC;YACJ,CAAC,CAAC;YAEFf,KAAI,CAACoC,kBAAkB,CAACJ,WAAW,CAAC,GAClCE,mBAAiB,CAACE,kBAAkB;YAEtCpC,KAAI,CAACqC,4BAA4B,CAACL,WAAW,CAAC,GAC5CE,mBAAiB,CAACG,4BAA4B;YAEhDrC,KAAI,CAACsC,WAAW,GAAG,oBAAM,EACvB,EAAE,EACFtC,KAAI,CAACsC,WAAW,EAChBJ,mBAAiB,CAACI,WAAW,CACvB;YAERtC,KAAI,CAACuC,SAAS,GAAGL,mBAAiB,CAACK,SAAS,IAAIvC,KAAI,CAACuC,SAAS;YAE9DvC,KAAI,CAACwC,kBAAkB,CAACR,WAAW,CAAC,GAClCE,mBAAiB,CAACO,cAAc;;QAEtC,CAAC,CAAC;MACJ,CAAC,CACF;MAEDzC,KAAI,CAACuB,WAAW,GAAGP,gBAAgB,CAACO,WAAW;MAE/C,IACE,CAAC,qBAAO,EAACvB,KAAI,CAACwB,qBAAqB,CAAC,IACpC,CAACxB,KAAI,CAACH,MAAM,CAACd,6BAA6B,EAC1C;QACA,IAAM2D,cAAc,GAAG,iBAAG,EAAC1C,KAAI,CAACwB,qBAAqB,EAAE,UAACmB,KAAK;UAC3D,OAAOA,KAAK,CAACC,OAAO;QACtB,CAAC,CAAC;QACF,IAAMC,oBAAoB,GAAGH,cAAc,CAACtC,IAAI,CAC9C,2BAA2B,CAC5B;QACD,MAAM,IAAIQ,KAAK,CACb,2CAA2C,GAAGiC,oBAAoB,CACnE;;MAGH;MACA,qBAAO,EAAC7C,KAAI,CAAC0B,sBAAsB,EAAE,UAACoB,iBAAiB;QACrD,yBAAa,EAACA,iBAAiB,CAACF,OAAO,CAAC;MAC1C,CAAC,CAAC;MAEF5C,KAAI,CAACe,UAAU,CAAC,sCAAsC,EAAE;QACtD;QACA;QACA;QACA,IAAIG,sBAAc,EAAE;UAClBlB,KAAI,CAAC+C,SAAS,GAAQC,kBAAQ;UAC9BhD,KAAI,CAACiD,KAAK,GAAGjD,KAAI,CAACkD,aAAa;SAChC,MAAM;UACLlD,KAAI,CAACmD,eAAe,GAAGC,cAAI;UAC3BpD,KAAI,CAACiD,KAAK,GAAGjD,KAAI,CAACqD,aAAa;;QAGjC,IAAIpC,iBAAiB,EAAE;UACrBjB,KAAI,CAACsD,WAAW,GAAGF,cAAI;;QAGzB,IAAIpD,KAAI,CAACmB,eAAe,KAAK,KAAK,EAAE;UAClCnB,KAAI,CAACuD,gBAAgB,GAAGP,kBAAQ;;QAGlC,IAAIhD,KAAI,CAACqB,aAAa,KAAK,KAAK,EAAE;UAChCrB,KAAI,CAACwD,gCAAgC,GAAGJ,cAAI;;QAG9C,IAAI,OAAO,CAAChC,IAAI,CAACpB,KAAI,CAACH,MAAM,CAACb,gBAAgB,CAAC,EAAE;UAC9CgB,KAAI,CAACyD,mBAAmB,GAAGzD,KAAI,CAAC0D,eAAe;SAChD,MAAM,IAAI,YAAY,CAACtC,IAAI,CAACpB,KAAI,CAACH,MAAM,CAACb,gBAAgB,CAAC,EAAE;UAC1DgB,KAAI,CAACyD,mBAAmB,GAAGzD,KAAI,CAAC2D,oBAAoB;SACrD,MAAM,IAAI,aAAa,CAACvC,IAAI,CAACpB,KAAI,CAACH,MAAM,CAACb,gBAAgB,CAAC,EAAE;UAC3DgB,KAAI,CAACyD,mBAAmB,GAAGzD,KAAI,CAAC4D,qBAAqB;SACtD,MAAM;UACL,MAAMhD,KAAK,CACT,sDAA8CZ,KAAI,CAACH,MAAM,CAACb,gBAAgB,OAAG,CAC9E;;QAGH,IAAIgB,KAAI,CAACuC,SAAS,EAAE;UAClBvC,KAAI,CAAC6D,QAAQ,GAAG7D,KAAI,CAAC8D,iBAAiB;UACtC9D,KAAI,CAAC+D,aAAa,GAAG/D,KAAI,CAACgE,uBAAuB;SAClD,MAAM;UACLhE,KAAI,CAAC6D,QAAQ,GAAG7D,KAAI,CAACiE,yBAAyB;UAC9CjE,KAAI,CAAC+D,aAAa,GAAG/D,KAAI,CAACkE,qBAAqB;;MAEnD,CAAC,CAAC;MAEFlE,KAAI,CAACe,UAAU,CAAC,8BAA8B,EAAE;QAC9C,IAAMoD,gBAAgB,GAAG,oBAAM,EAC7BnE,KAAI,CAACwC,kBAAkB,EACvB,UAAC4B,iBAAiB,EAAE3B,cAAc,EAAE4B,QAAQ;UAC1C,IAAI5B,cAAc,KAAK,KAAK,EAAE;YAC5B2B,iBAAiB,CAACnC,IAAI,CAACoC,QAAQ,CAAC;;UAElC,OAAOD,iBAAiB;QAC1B,CAAC,EACD,EAAc,CACf;QAED,IAAIvE,MAAM,CAACV,mBAAmB,IAAI,CAAC,qBAAO,EAACgF,gBAAgB,CAAC,EAAE;UAC5D,MAAMvD,KAAK,CACT,yBAAkBuD,gBAAgB,CAAC/D,IAAI,CACrC,IAAI,CACL,8BAA2B,GAC1B,6HAA6H,GAC7H,2EAA2E,CAC9E;;MAEL,CAAC,CAAC;MAEFJ,KAAI,CAACe,UAAU,CAAC,wBAAwB,EAAE;QACxC,2CAAsB,GAAE;MAC1B,CAAC,CAAC;MAEFf,KAAI,CAACe,UAAU,CAAC,kBAAkB,EAAE;QAClC,4BAAgB,EAACf,KAAI,CAAC;MACxB,CAAC,CAAC;IACJ,CAAC,CAAC;EACJ;EAEOsE,wBAAQ,GAAf,UACEC,IAAY,EACZC,WAAsC;IAAtC;MAAAA,cAAsB,IAAI,CAACjD,WAAW;IAAA;IAEtC,IAAI,CAAC,qBAAO,EAAC,IAAI,CAACC,qBAAqB,CAAC,EAAE;MACxC,IAAMkB,cAAc,GAAG,iBAAG,EAAC,IAAI,CAAClB,qBAAqB,EAAE,UAACmB,KAAK;QAC3D,OAAOA,KAAK,CAACC,OAAO;MACtB,CAAC,CAAC;MACF,IAAMC,oBAAoB,GAAGH,cAAc,CAACtC,IAAI,CAC9C,2BAA2B,CAC5B;MACD,MAAM,IAAIQ,KAAK,CACb,sEAAsE,GACpEiC,oBAAoB,CACvB;;IAGH,OAAO,IAAI,CAAC4B,gBAAgB,CAACF,IAAI,EAAEC,WAAW,CAAC;EACjD,CAAC;EAED;EACA;EACA;EACA;EACQF,gCAAgB,GAAxB,UAAyBC,IAAY,EAAEC,WAAmB;IAA1D;IACE,IAAIE,CAAC,EACHC,CAAC,EACDC,CAAC,EACDC,aAAa,EACbC,SAAS,EACTC,YAA2B,EAC3BC,OAAO,EACPC,UAAU,EACVC,WAAW,EACXC,KAAK,EACLC,OAAO,EACPC,QAAgB,EAChBC,SAAS,EACTC,WAAW,EACXC,GAAG,EACHvC,KAAK;IACP,IAAMwC,OAAO,GAAGlB,IAAI;IACpB,IAAMmB,SAAS,GAAGD,OAAO,CAACE,MAAM;IAChC,IAAIC,MAAM,GAAG,CAAC;IACd,IAAIC,kBAAkB,GAAG,CAAC;IAC1B;IACA;IACA;IACA;IACA,IAAMC,qBAAqB,GAAG,IAAI,CAACvD,SAAS,GACxC,CAAC,CAAC;IAAA,EACFwD,IAAI,CAACC,KAAK,CAACzB,IAAI,CAACoB,MAAM,GAAG,EAAE,CAAC;IAChC,IAAMM,aAAa,GAAG,IAAI9F,KAAK,CAAC2F,qBAAqB,CAAC;IACtD,IAAMI,MAAM,GAAmB,EAAE;IACjC,IAAIC,IAAI,GAAG,IAAI,CAAChF,eAAe,GAAG,CAAC,GAAGiF,SAAS;IAC/C,IAAIC,MAAM,GAAG,IAAI,CAAClF,eAAe,GAAG,CAAC,GAAGiF,SAAS;IACjD,IAAME,MAAM,GAAQ,4BAAgB,EAAC,IAAI,CAAChE,WAAW,CAAC;IACtD,IAAMiE,UAAU,GAAG,IAAI,CAACpF,eAAe;IACvC,IAAMqF,qBAAqB,GAAG,IAAI,CAAC3G,MAAM,CAACZ,sBAAsB;IAEhE,IAAIwH,sBAAsB,GAAG,CAAC;IAC9B,IAAIrE,kBAAkB,GAAqB,EAAE;IAC7C,IAAIsE,gCAAgC,GAEhC,EAAE;IAEN,IAAMC,SAAS,GAAa,EAAE;IAE9B,IAAMC,UAAU,GAAqB,EAAE;IACvClH,MAAM,CAACC,MAAM,CAACiH,UAAU,CAAC;IACzB,IAAIC,mBAA4D;IAEhE,SAASC,uBAAuB;MAC9B,OAAO1E,kBAAkB;IAC3B;IAEA,SAAS2E,4BAA4B,CAACC,QAAgB;MACpD,IAAMC,gBAAgB,GAAG,oCAAwB,EAACD,QAAQ,CAAC;MAC3D,IAAME,gBAAgB,GACpBR,gCAAgC,CAACO,gBAAgB,CAAC;MACpD,IAAIC,gBAAgB,KAAKd,SAAS,EAAE;QAClC,OAAOQ,UAAU;OAClB,MAAM;QACL,OAAOM,gBAAgB;;IAE3B;IAEA,IAAMC,QAAQ,GAAG,UAACC,QAAgB;MAChC;MACA,IACET,SAAS,CAAChB,MAAM,KAAK,CAAC;MACtB;MACA;MACAyB,QAAQ,CAACC,SAAS,CAACC,SAAS,KAAKlB,SAAS,EAC1C;QACA;QACA;QACA,IAAMmB,KAAG,GACPvH,KAAI,CAACH,MAAM,CAACR,oBAAoB,CAACmI,gCAAgC,CAC/DJ,QAAQ,CACT;QAEHlB,MAAM,CAACjE,IAAI,CAAC;UACV2D,MAAM,EAAEwB,QAAQ,CAACK,WAAW;UAC5BtB,IAAI,EAAEiB,QAAQ,CAACM,SAAS;UACxBrB,MAAM,EAAEe,QAAQ,CAACO,WAAW;UAC5BhC,MAAM,EAAEyB,QAAQ,CAACQ,KAAK,CAACjC,MAAM;UAC7B/C,OAAO,EAAE2E;SACV,CAAC;OACH,MAAM;QACLZ,SAAS,CAACkB,GAAG,EAAE;QACf,IAAMC,OAAO,GAAG,kBAAI,EAACnB,SAAS,CAAE;QAChCvE,kBAAkB,GAAGpC,KAAI,CAACoC,kBAAkB,CAAC0F,OAAO,CAAC;QACrDpB,gCAAgC,GAC9B1G,KAAI,CAACqC,4BAA4B,CAACyF,OAAO,CAAC;QAC5CrB,sBAAsB,GAAGrE,kBAAkB,CAACuD,MAAM;QAClD,IAAMoC,kBAAkB,GACtB/H,KAAI,CAACwC,kBAAkB,CAACsF,OAAO,CAAC,IAAI9H,KAAI,CAACH,MAAM,CAACT,QAAQ,KAAK,KAAK;QAEpE,IAAIsH,gCAAgC,IAAIqB,kBAAkB,EAAE;UAC1DlB,mBAAmB,GAAGE,4BAA4B;SACnD,MAAM;UACLF,mBAAmB,GAAGC,uBAAuB;;;IAGnD,CAAC;IAED,SAASkB,SAAS,CAAcF,OAAe;MAC7CnB,SAAS,CAAC1E,IAAI,CAAC6F,OAAO,CAAC;MACvBpB,gCAAgC,GAC9B,IAAI,CAACrE,4BAA4B,CAACyF,OAAO,CAAC;MAE5C1F,kBAAkB,GAAG,IAAI,CAACA,kBAAkB,CAAC0F,OAAO,CAAC;MACrDrB,sBAAsB,GAAGrE,kBAAkB,CAACuD,MAAM;MAElDc,sBAAsB,GAAGrE,kBAAkB,CAACuD,MAAM;MAClD,IAAMoC,kBAAkB,GACtB,IAAI,CAACvF,kBAAkB,CAACsF,OAAO,CAAC,IAAI,IAAI,CAACjI,MAAM,CAACT,QAAQ,KAAK,KAAK;MAEpE,IAAIsH,gCAAgC,IAAIqB,kBAAkB,EAAE;QAC1DlB,mBAAmB,GAAGE,4BAA4B;OACnD,MAAM;QACLF,mBAAmB,GAAGC,uBAAuB;;IAEjD;IAEA;IACA;IACAkB,SAAS,CAACC,IAAI,CAAC,IAAI,EAAEzD,WAAW,CAAC;IAEjC,IAAI0D,UAA2B;IAE/B,IAAMzI,eAAe,GAAG,IAAI,CAACI,MAAM,CAACJ,eAAe;IAEnD,OAAOmG,MAAM,GAAGF,SAAS,EAAE;MACzBX,YAAY,GAAG,IAAI;MAEnB,IAAMoD,YAAY,GAAG1C,OAAO,CAAC2C,UAAU,CAACxC,MAAM,CAAC;MAC/C,IAAMyC,wBAAwB,GAAGxB,mBAAmB,CAACsB,YAAY,CAAC;MAClE,IAAMG,oBAAoB,GAAGD,wBAAwB,CAAC1C,MAAM;MAE5D,KAAKjB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG4D,oBAAoB,EAAE5D,CAAC,EAAE,EAAE;QACzCwD,UAAU,GAAGG,wBAAwB,CAAC3D,CAAC,CAAC;QACxC,IAAM6D,WAAW,GAAGL,UAAU,CAACM,OAAO;QACtCxD,OAAO,GAAG,IAAI;QAEd;QACA,IAAMyD,cAAc,GAAGP,UAAU,CAACQ,KAAK;QACvC,IAAID,cAAc,KAAK,KAAK,EAAE;UAC5B,IAAIN,YAAY,KAAKM,cAAc,EAAE;YACnC;YACA1D,YAAY,GAAGwD,WAAqB;;SAEvC,MAAM,IAAIL,UAAU,CAACS,QAAQ,KAAK,IAAI,EAAE;UACvC1F,KAAK,GAAIsF,WAA2B,CAACK,IAAI,CACvCnD,OAAO,EACPG,MAAM,EACNK,aAAa,EACbK,MAAM,CACP;UACD,IAAIrD,KAAK,KAAK,IAAI,EAAE;YAClB8B,YAAY,GAAG9B,KAAK,CAAC,CAAC,CAAC;YACvB,IAAKA,KAAoC,CAAC+B,OAAO,KAAKoB,SAAS,EAAE;cAC/DpB,OAAO,GAAI/B,KAAoC,CAAC+B,OAAO;;WAE1D,MAAM;YACLD,YAAY,GAAG,IAAI;;SAEtB,MAAM;UACL,IAAI,CAAC5B,eAAe,CAACoF,WAAqB,EAAE3C,MAAM,CAAC;UACnDb,YAAY,GAAG,IAAI,CAAC9B,KAAK,CAACsF,WAAqB,EAAEhE,IAAI,EAAEqB,MAAM,CAAC;;QAGhE,IAAIb,YAAY,KAAK,IAAI,EAAE;UACzB;UACA;UACAD,SAAS,GAAGoD,UAAU,CAACpD,SAAS;UAChC,IAAIA,SAAS,KAAKsB,SAAS,EAAE;YAC3B;YACA;YACA,IAAMyC,eAAe,GAAG/D,SAAS,CAACa,MAAM;YACxC,KAAKf,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGiE,eAAe,EAAEjE,CAAC,EAAE,EAAE;cACpC,IAAMkE,eAAe,GAAG1G,kBAAkB,CAAC0C,SAAS,CAACF,CAAC,CAAC,CAAC;cACxD,IAAMmE,gBAAgB,GAAGD,eAAe,CAACN,OAAO;cAChDvD,UAAU,GAAG,IAAI;cAEjB;cACA;cACA,IAAI6D,eAAe,CAACH,QAAQ,KAAK,IAAI,EAAE;gBACrC1F,KAAK,GAAI8F,gBAAgC,CAACH,IAAI,CAC5CnD,OAAO,EACPG,MAAM,EACNK,aAAa,EACbK,MAAM,CACP;gBACD,IAAIrD,KAAK,KAAK,IAAI,EAAE;kBAClB4B,aAAa,GAAG5B,KAAK,CAAC,CAAC,CAAC;kBACxB,IACGA,KAAoC,CAAC+B,OAAO,KAAKoB,SAAS,EAC3D;oBACAnB,UAAU,GAAIhC,KAAoC,CAAC+B,OAAO;;iBAE7D,MAAM;kBACLH,aAAa,GAAG,IAAI;;eAEvB,MAAM;gBACL,IAAI,CAAC1B,eAAe,CAAC4F,gBAA0B,EAAEnD,MAAM,CAAC;gBACxDf,aAAa,GAAG,IAAI,CAAC5B,KAAK,CACxB8F,gBAA0B,EAC1BxE,IAAI,EACJqB,MAAM,CACP;;cAGH,IAAIf,aAAa,IAAIA,aAAa,CAACc,MAAM,GAAGZ,YAAY,CAACY,MAAM,EAAE;gBAC/DZ,YAAY,GAAGF,aAAa;gBAC5BG,OAAO,GAAGC,UAAU;gBACpBiD,UAAU,GAAGY,eAAe;gBAC5B;gBACA;gBACA;;;;UAIN;;;MAIJ;MACA,IAAI/D,YAAY,KAAK,IAAI,EAAE;QACzBG,WAAW,GAAGH,YAAY,CAACY,MAAM;QACjCR,KAAK,GAAG+C,UAAU,CAAC/C,KAAK;QACxB,IAAIA,KAAK,KAAKiB,SAAS,EAAE;UACvBhB,OAAO,GAAG8C,UAAU,CAACc,YAAY;UACjC;UACA;UACA3D,QAAQ,GAAG,IAAI,CAAC5B,mBAAmB,CACjCsB,YAAY,EACZa,MAAM,EACNR,OAAO,EACP8C,UAAU,CAACb,SAAS,EACpBlB,IAAI,EACJE,MAAM,EACNnB,WAAW,CACZ;UAED,IAAI,CAACnB,aAAa,CAACsB,QAAQ,EAAEL,OAAO,CAAC;UAErC;UACA,IAAIG,KAAK,KAAK,KAAK,EAAE;YACnBU,kBAAkB,GAAG,IAAI,CAAChC,QAAQ,CAChCoC,aAAa,EACbJ,kBAAkB,EAClBR,QAAQ,CACT;WACF,MAAM;YACLiB,MAAM,CAACnB,KAAK,CAAC,CAAClD,IAAI,CAACoD,QAAQ,CAAC;;;QAGhCd,IAAI,GAAG,IAAI,CAACxB,SAAS,CAACwB,IAAI,EAAEW,WAAW,CAAC;QACxCU,MAAM,GAAGA,MAAM,GAAGV,WAAW;QAE7B;QACAmB,MAAM,GAAG,IAAI,CAAC9C,gBAAgB,CAAC8C,MAAO,EAAEnB,WAAW,CAAC;QAEpD,IAAIqB,UAAU,KAAK,IAAI,IAAI2B,UAAU,CAACe,iBAAiB,KAAK,IAAI,EAAE;UAChE,IAAIC,eAAe,GAAG,CAAC;UACvB,IAAIC,eAAe;UACnB,IAAIC,eAAe,SAAQ;UAC3B5C,qBAAqB,CAAC6C,SAAS,GAAG,CAAC;UACnC,GAAG;YACDF,eAAe,GAAG3C,qBAAqB,CAACpF,IAAI,CAAC2D,YAAY,CAAC;YAC1D,IAAIoE,eAAe,KAAK,IAAI,EAAE;cAC5BC,eAAe,GAAG5C,qBAAqB,CAAC6C,SAAS,GAAG,CAAC;cACrDH,eAAe,EAAE;;WAEpB,QAAQC,eAAe,KAAK,IAAI;UAEjC,IAAID,eAAe,KAAK,CAAC,EAAE;YACzB/C,IAAI,GAAGA,IAAK,GAAG+C,eAAe;YAC9B7C,MAAM,GAAGnB,WAAW,GAAGkE,eAAgB;YACvC,IAAI,CAAC5F,gCAAgC,CACnC6B,QAAS,EACTF,KAAM,EACNiE,eAAgB,EAChBF,eAAe,EACf/C,IAAI,EACJE,MAAM,EACNnB,WAAW,CACZ;;;QAGL;QACA,IAAI,CAAC5B,WAAW,CAAC4E,UAAU,EAAEf,QAAQ,EAAEa,SAAS,EAAE3C,QAAS,CAAC;OAC7D,MAAM;QACL;QACA,IAAMiE,gBAAgB,GAAG1D,MAAM;QAC/B,IAAM2D,SAAS,GAAGpD,IAAI;QACtB,IAAMqD,WAAW,GAAGnD,MAAM;QAC1B,IAAIoD,gBAAgB,GAAGhK,eAAe,KAAK,KAAK;QAEhD,OAAOgK,gBAAgB,KAAK,KAAK,IAAI7D,MAAM,GAAGF,SAAS,EAAE;UACvD;UACAnB,IAAI,GAAG,IAAI,CAACxB,SAAS,CAACwB,IAAI,EAAE,CAAC,CAAC;UAC9BqB,MAAM,EAAE;UACR,KAAKjB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8B,sBAAsB,EAAE9B,CAAC,EAAE,EAAE;YAC3C,IAAM+E,YAAU,GAAGtH,kBAAkB,CAACuC,CAAC,CAAC;YACxC,IAAM4D,WAAW,GAAGmB,YAAU,CAAClB,OAAO;YAEtC;YACA,IAAMC,cAAc,GAAGiB,YAAU,CAAChB,KAAK;YACvC,IAAID,cAAc,KAAK,KAAK,EAAE;cAC5B,IAAIhD,OAAO,CAAC2C,UAAU,CAACxC,MAAM,CAAC,KAAK6C,cAAc,EAAE;gBACjD;gBACAgB,gBAAgB,GAAG,IAAI;;aAE1B,MAAM,IAAIC,YAAU,CAACf,QAAQ,KAAK,IAAI,EAAE;cACvCc,gBAAgB,GACblB,WAA2B,CAACK,IAAI,CAC/BnD,OAAO,EACPG,MAAM,EACNK,aAAa,EACbK,MAAM,CACP,KAAK,IAAI;aACb,MAAM;cACL,IAAI,CAACnD,eAAe,CAACoF,WAAqB,EAAE3C,MAAM,CAAC;cACnD6D,gBAAgB,GAAIlB,WAAsB,CAACK,IAAI,CAACrE,IAAI,CAAC,KAAK,IAAI;;YAGhE,IAAIkF,gBAAgB,KAAK,IAAI,EAAE;cAC7B;;;;QAKNnE,SAAS,GAAGM,MAAM,GAAG0D,gBAAgB;QACrC;QACA9D,GAAG,GAAG,IAAI,CAAC3F,MAAM,CAACR,oBAAoB,CAACsK,gCAAgC,CACrElE,OAAO,EACP6D,gBAAgB,EAChBhE,SAAS,EACTiE,SAAS,EACTC,WAAW,CACZ;QACDtD,MAAM,CAACjE,IAAI,CAAC;UACV2D,MAAM,EAAE0D,gBAAgB;UACxBnD,IAAI,EAAEoD,SAAS;UACflD,MAAM,EAAEmD,WAAW;UACnB7D,MAAM,EAAEL,SAAS;UACjB1C,OAAO,EAAE4C;SACV,CAAC;QAEF,IAAI/F,eAAe,KAAK,KAAK,EAAE;UAC7B;;;;IAKN;IACA;IACA,IAAI,CAAC,IAAI,CAAC8C,SAAS,EAAE;MACnB;MACA0D,aAAa,CAACN,MAAM,GAAGE,kBAAkB;;IAG3C,OAAO;MACL+D,MAAM,EAAE3D,aAAa;MACrBK,MAAM,EAAEA,MAAM;MACdJ,MAAM,EAAEA;KACT;EACH,CAAC;EAEO5B,2BAAW,GAAnB,UACEzE,MAAsB,EACtBsH,QAA+B,EAC/Ba,SAAkD,EAClD3C,QAAgB;IAEhB,IAAIxF,MAAM,CAACgI,GAAG,KAAK,IAAI,EAAE;MACvB;MACA;MACA,IAAMgC,QAAQ,GAAGhK,MAAM,CAACoC,IAAI;MAC5BkF,QAAQ,CAAC9B,QAAQ,CAAC;MAClB,IAAIwE,QAAQ,KAAKzD,SAAS,EAAE;QAC1B4B,SAAS,CAACC,IAAI,CAAC,IAAI,EAAE4B,QAAQ,CAAC;;KAEjC,MAAM,IAAIhK,MAAM,CAACoC,IAAI,KAAKmE,SAAS,EAAE;MACpC4B,SAAS,CAACC,IAAI,CAAC,IAAI,EAAEpI,MAAM,CAACoC,IAAI,CAAC;;EAErC,CAAC;EAEOqC,yBAAS,GAAjB,UAAkBC,IAAY,EAAEoB,MAAc;IAC5C,OAAOpB,IAAI,CAACuF,SAAS,CAACnE,MAAM,CAAC;EAC/B,CAAC;EAEOrB,+BAAe,GAAvB,UAAwByF,MAAc,EAAEC,YAAoB;IAC1DD,MAAM,CAACV,SAAS,GAAGW,YAAY;EACjC,CAAC;EAED;EACQ1F,gDAAgC,GAAxC,UACEe,QAAgB,EAChBF,KAAqB,EACrB8E,SAAiB,EACjBf,eAAuB,EACvB/C,IAAY,EACZE,MAAc,EACdnB,WAAmB;IAEnB,IAAIgF,YAAY,EAAEC,gBAAgB;IAClC,IAAIhF,KAAK,KAAKiB,SAAS,EAAE;MACvB;MACA8D,YAAY,GAAGD,SAAS,KAAK/E,WAAW,GAAG,CAAC;MAC5CiF,gBAAgB,GAAGD,YAAY,GAAG,CAAC,CAAC,GAAG,CAAC;MACxC,IAAI,EAAEhB,eAAe,KAAK,CAAC,IAAIgB,YAAY,KAAK,IAAI,CAAC,EAAE;QACrD;QACA7E,QAAQ,CAAC+E,OAAO,GAAGjE,IAAI,GAAGgE,gBAAgB;QAC1C;QACA;QACA9E,QAAQ,CAACgF,SAAS,GAAGhE,MAAM,GAAG,CAAC,GAAG,CAAC8D,gBAAgB;;MAErD;;EAEJ,CAAC;;EAEO7F,gCAAgB,GAAxB,UAAyBgG,SAAiB,EAAEpF,WAAmB;IAC7D,OAAOoF,SAAS,GAAGpF,WAAW;EAChC,CAAC;EAMOZ,qCAAqB,GAA7B,UACEsD,KAAa,EACbH,WAAmB,EACnBuB,YAAoB,EACpB3B,SAAoB;IAEpB,OAAO;MACLO,KAAK;MACLH,WAAW;MACXuB,YAAY;MACZ3B,SAAS;KACV;EACH,CAAC;EAEO/C,oCAAoB,GAA5B,UACEsD,KAAa,EACbH,WAAmB,EACnBuB,YAAoB,EACpB3B,SAAoB,EACpBK,SAAiB,EACjBC,WAAmB;IAEnB,OAAO;MACLC,KAAK;MACLH,WAAW;MACXC,SAAS;MACTC,WAAW;MACXqB,YAAY;MACZ3B,SAAS;KACV;EACH,CAAC;EAEO/C,+BAAe,GAAvB,UACEsD,KAAa,EACbH,WAAmB,EACnBuB,YAAoB,EACpB3B,SAAoB,EACpBK,SAAiB,EACjBC,WAAmB,EACnBzC,WAAmB;IAEnB,OAAO;MACL0C,KAAK;MACLH,WAAW;MACX8C,SAAS,EAAE9C,WAAW,GAAGvC,WAAW,GAAG,CAAC;MACxCwC,SAAS;MACT0C,OAAO,EAAE1C,SAAS;MAClBC,WAAW;MACX0C,SAAS,EAAE1C,WAAW,GAAGzC,WAAW,GAAG,CAAC;MACxC8D,YAAY;MACZ3B,SAAS;KACV;EACH,CAAC;EAUO/C,iCAAiB,GAAzB,UACEkG,WAAqB,EACrBC,KAAa,EACbC,UAAkB;IAElBF,WAAW,CAACvI,IAAI,CAACyI,UAAU,CAAC;IAC5B,OAAOD,KAAK;EACd,CAAC;EAEOnG,yCAAyB,GAAjC,UACEkG,WAAqB,EACrBC,KAAa,EACbC,UAAkB;IAElBF,WAAW,CAACC,KAAK,CAAC,GAAGC,UAAU;IAC/BD,KAAK,EAAE;IACP,OAAOA,KAAK;EACd,CAAC;EAKOnG,qCAAqB,GAA7B,UAA8BqG,KAAa,EAAE3F,OAAY,GAAS,CAAC;EAE3DV,uCAAuB,GAA/B,UAAgCqG,KAAa,EAAE3F,OAAY;IACzD,IAAIA,OAAO,KAAK,IAAI,EAAE;MACpB2F,KAAK,CAAC3F,OAAO,GAAGA,OAAO;;EAE3B,CAAC;EASOV,6BAAa,GAArB,UACEkE,OAAe,EACfjE,IAAY,EACZqB,MAAc;IAEd,IAAMgF,KAAK,GAAGpC,OAAO,CAACpH,IAAI,CAACmD,IAAI,CAAC;IAChC,IAAIqG,KAAK,KAAK,IAAI,EAAE;MAClB,OAAOrG,IAAI,CAACuF,SAAS,CAAClE,MAAM,EAAE4C,OAAO,CAACa,SAAS,CAAC;;IAElD,OAAO,IAAI;EACb,CAAC;EAEO/E,6BAAa,GAArB,UAAsBkE,OAAe,EAAEjE,IAAY;IACjD,IAAMsG,WAAW,GAAGrC,OAAO,CAACI,IAAI,CAACrE,IAAI,CAAC;IACtC,OAAOsG,WAAW,KAAK,IAAI,GAAGA,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI;EACrD,CAAC;EAv1BavG,aAAO,GACnB,iFAAiF,GACjF,6GAA6G;EAEjGA,QAAE,GAAG,gBAAgB;EA42BrC,YAAC;CAAA,EAj3BD;AAAazF","names":["LexerDefinitionErrorType","exports","DEFAULT_LEXER_CONFIG","deferDefinitionErrorsHandling","positionTracking","lineTerminatorsPattern","lineTerminatorCharacters","ensureOptimizations","safeMode","errorMessageProvider","lexer_errors_public_1","traceInitPerf","skipValidations","recoveryEnabled","Object","freeze","lexerDefinition","config","phaseDesc","phaseImpl","_this","traceInitIndent","indent","Array","join","traceInitMaxIdent","console","log","time","value","traceMethod","warn","Error","traceInitVal","Infinity","TRACE_INIT","actualDefinition","hasOnlySingleMode","lexer_1","trackStartLines","test","trackEndLines","modes","defaultMode","lexerDefinitionErrors","concat","lexerDefinitionWarning","currModeValue","currModeName","currTokType","allModeNames","currModDef","currModName","push","currAnalyzeResult_1","tracer","patternIdxToConfig","charCodeToPatternIdxToConfig","emptyGroups","hasCustom","canModeBeOptimized","canBeOptimized","allErrMessages","error","message","allErrMessagesString","warningDescriptor","chopInput","identity_1","match","matchWithTest","updateLastIndex","noop_1","matchWithExec","handleModes","computeNewColumn","updateTokenEndLineColumnLocation","createTokenInstance","createFullToken","createStartOnlyToken","createOffsetOnlyToken","addToken","addTokenUsingPush","handlePayload","handlePayloadWithCustom","addTokenUsingMemberAccess","handlePayloadNoCustom","unOptimizedModes","cannotBeOptimized","modeName","Lexer","text","initialMode","tokenizeInternal","i","j","k","matchAltImage","longerAlt","matchedImage","payload","altPayload","imageLength","group","tokType","newToken","errLength","droppedChar","msg","orgText","orgLength","length","offset","matchedTokensIndex","guessedNumberOfTokens","Math","floor","matchedTokens","errors","line","undefined","column","groups","trackLines","lineTerminatorPattern","currModePatternsLength","currCharCodeToPatternIdxToConfig","modeStack","emptyArray","getPossiblePatterns","getPossiblePatternsSlow","getPossiblePatternsOptimized","charCode","optimizedCharIdx","possiblePatterns","pop_mode","popToken","tokenType","PUSH_MODE","msg_1","buildUnableToPopLexerModeMessage","startOffset","startLine","startColumn","image","pop","newMode","modeCanBeOptimized","push_mode","call","currConfig","nextCharCode","charCodeAt","chosenPatternIdxToConfig","chosenPatternsLength","currPattern","pattern","singleCharCode","short","isCustom","exec","longerAltLength","longerAltConfig","longerAltPattern","tokenTypeIdx","canLineTerminator","numOfLTsInMatch","foundTerminator","lastLTEndOffset","lastIndex","errorStartOffset","errorLine","errorColumn","foundResyncPoint","currConfig_1","buildUnexpectedCharactersMessage","tokens","pushMode","substring","regExp","newLastIndex","lastLTIdx","lastCharIsLT","fixForEndingInLT","endLine","endColumn","oldColumn","endOffset","tokenVector","index","tokenToAdd","token","found","regExpArray"],"sources":["/Users/tumolabsstudent/Desktop/app/node_modules/chevrotain/src/scan/lexer_public.ts"],"sourcesContent":["import {\n  analyzeTokenTypes,\n  charCodeToOptimizedIndex,\n  cloneEmptyGroups,\n  DEFAULT_MODE,\n  IAnalyzeResult,\n  IPatternConfig,\n  LineTerminatorOptimizedTester,\n  performRuntimeChecks,\n  performWarningRuntimeChecks,\n  SUPPORT_STICKY,\n  validatePatterns\n} from \"./lexer\"\nimport noop from \"lodash/noop\"\nimport isEmpty from \"lodash/isEmpty\"\nimport isArray from \"lodash/isArray\"\nimport last from \"lodash/last\"\nimport reject from \"lodash/reject\"\nimport map from \"lodash/map\"\nimport forEach from \"lodash/forEach\"\nimport keys from \"lodash/keys\"\nimport isUndefined from \"lodash/isUndefined\"\nimport identity from \"lodash/identity\"\nimport assign from \"lodash/assign\"\nimport reduce from \"lodash/reduce\"\nimport clone from \"lodash/clone\"\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\"\nimport { augmentTokenTypes } from \"./tokens\"\nimport {\n  CustomPatternMatcherFunc,\n  CustomPatternMatcherReturn,\n  ILexerConfig,\n  ILexerDefinitionError,\n  ILexingError,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType\n} from \"@chevrotain/types\"\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public\"\nimport { clearRegExpParserCache } from \"./reg_exp_parser\"\n\nexport interface ILexingResult {\n  tokens: IToken[]\n  groups: { [groupName: string]: IToken[] }\n  errors: ILexingError[]\n}\n\nexport enum LexerDefinitionErrorType {\n  MISSING_PATTERN,\n  INVALID_PATTERN,\n  EOI_ANCHOR_FOUND,\n  UNSUPPORTED_FLAGS_FOUND,\n  DUPLICATE_PATTERNS_FOUND,\n  INVALID_GROUP_TYPE_FOUND,\n  PUSH_MODE_DOES_NOT_EXIST,\n  MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n  MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n  MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n  LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n  SOI_ANCHOR_FOUND,\n  EMPTY_MATCH_PATTERN,\n  NO_LINE_BREAKS_FLAGS,\n  UNREACHABLE_PATTERN,\n  IDENTIFY_TERMINATOR,\n  CUSTOM_LINE_BREAK,\n  MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n}\n\nexport interface IRegExpExec {\n  exec: CustomPatternMatcherFunc\n}\n\nconst DEFAULT_LEXER_CONFIG: Required<ILexerConfig> = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true\n}\n\nObject.freeze(DEFAULT_LEXER_CONFIG)\n\nexport class Lexer {\n  public static SKIPPED =\n    \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\"\n\n  public static NA = /NOT_APPLICABLE/\n  public lexerDefinitionErrors: ILexerDefinitionError[] = []\n  public lexerDefinitionWarning: ILexerDefinitionError[] = []\n\n  protected patternIdxToConfig: Record<string, IPatternConfig[]> = {}\n  protected charCodeToPatternIdxToConfig: {\n    [modeName: string]: { [charCode: number]: IPatternConfig[] }\n  } = {}\n\n  protected modes: string[] = []\n  protected defaultMode!: string\n  protected emptyGroups: { [groupName: string]: IToken } = {}\n\n  private config: Required<ILexerConfig>\n  private trackStartLines: boolean = true\n  private trackEndLines: boolean = true\n  private hasCustom: boolean = false\n  private canModeBeOptimized: Record<string, boolean> = {}\n\n  private traceInitPerf!: boolean | number\n  private traceInitMaxIdent!: number\n  private traceInitIndent: number\n\n  constructor(\n    protected lexerDefinition: TokenType[] | IMultiModeLexerDefinition,\n    config: ILexerConfig = DEFAULT_LEXER_CONFIG\n  ) {\n    if (typeof config === \"boolean\") {\n      throw Error(\n        \"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n          \"a boolean 2nd argument is no longer supported\"\n      )\n    }\n\n    // todo: defaults func?\n    this.config = assign({}, DEFAULT_LEXER_CONFIG, config) as any\n\n    const traceInitVal = this.config.traceInitPerf\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity\n      this.traceInitPerf = true\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal\n      this.traceInitPerf = true\n    }\n    this.traceInitIndent = -1\n\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition!: IMultiModeLexerDefinition\n      let hasOnlySingleMode = true\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (\n          this.config.lineTerminatorsPattern ===\n          DEFAULT_LEXER_CONFIG.lineTerminatorsPattern\n        ) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester\n        } else {\n          if (\n            this.config.lineTerminatorCharacters ===\n            DEFAULT_LEXER_CONFIG.lineTerminatorCharacters\n          ) {\n            throw Error(\n              \"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\"\n            )\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error(\n            '\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.'\n          )\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(\n          this.config.positionTracking\n        )\n        this.trackEndLines = /full/i.test(this.config.positionTracking)\n\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (isArray(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone(lexerDefinition) },\n            defaultMode: DEFAULT_MODE\n          }\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false\n          actualDefinition = clone(<IMultiModeLexerDefinition>lexerDefinition)\n        }\n      })\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n            performRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters\n            )\n          )\n        })\n\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(\n            performWarningRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters\n            )\n          )\n        })\n      }\n\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes\n        ? actualDefinition.modes\n        : {}\n\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject<TokenType>(\n          currModeValue,\n          (currTokType) => isUndefined(currTokType)\n        )\n      })\n\n      const allModeNames = keys(actualDefinition.modes)\n\n      forEach(\n        actualDefinition.modes,\n        (currModDef: TokenType[], currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName)\n\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n                  validatePatterns(currModDef, allModeNames)\n                )\n              })\n            }\n\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef)\n\n              let currAnalyzeResult!: IAnalyzeResult\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters:\n                    this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT\n                })\n              })\n\n              this.patternIdxToConfig[currModName] =\n                currAnalyzeResult.patternIdxToConfig\n\n              this.charCodeToPatternIdxToConfig[currModName] =\n                currAnalyzeResult.charCodeToPatternIdxToConfig\n\n              this.emptyGroups = assign(\n                {},\n                this.emptyGroups,\n                currAnalyzeResult.emptyGroups\n              ) as any\n\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom\n\n              this.canModeBeOptimized[currModName] =\n                currAnalyzeResult.canBeOptimized\n            }\n          })\n        }\n      )\n\n      this.defaultMode = actualDefinition.defaultMode\n\n      if (\n        !isEmpty(this.lexerDefinitionErrors) &&\n        !this.config.deferDefinitionErrorsHandling\n      ) {\n        const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n          return error.message\n        })\n        const allErrMessagesString = allErrMessages.join(\n          \"-----------------------\\n\"\n        )\n        throw new Error(\n          \"Errors detected in definition of Lexer:\\n\" + allErrMessagesString\n        )\n      }\n\n      // Only print warning if there are no errors, This will avoid pl\n      forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message)\n      })\n\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (SUPPORT_STICKY) {\n          this.chopInput = <any>identity\n          this.match = this.matchWithTest\n        } else {\n          this.updateLastIndex = noop\n          this.match = this.matchWithExec\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken\n        } else {\n          throw Error(\n            `Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`\n          )\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush\n          this.handlePayload = this.handlePayloadWithCustom\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess\n          this.handlePayload = this.handlePayloadNoCustom\n        }\n      })\n\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce(\n          this.canModeBeOptimized,\n          (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName)\n            }\n            return cannotBeOptimized\n          },\n          [] as string[]\n        )\n\n        if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n          throw Error(\n            `Lexer Modes: < ${unOptimizedModes.join(\n              \", \"\n            )} > cannot be optimized.\\n` +\n              '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n              \"\\t Or inspect the console log for details on how to resolve these issues.\"\n          )\n        }\n      })\n\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache()\n      })\n\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this)\n      })\n    })\n  }\n\n  public tokenize(\n    text: string,\n    initialMode: string = this.defaultMode\n  ): ILexingResult {\n    if (!isEmpty(this.lexerDefinitionErrors)) {\n      const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n        return error.message\n      })\n      const allErrMessagesString = allErrMessages.join(\n        \"-----------------------\\n\"\n      )\n      throw new Error(\n        \"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n          allErrMessagesString\n      )\n    }\n\n    return this.tokenizeInternal(text, initialMode)\n  }\n\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  private tokenizeInternal(text: string, initialMode: string): ILexingResult {\n    let i,\n      j,\n      k,\n      matchAltImage,\n      longerAlt,\n      matchedImage: string | null,\n      payload,\n      altPayload,\n      imageLength,\n      group,\n      tokType,\n      newToken: IToken,\n      errLength,\n      droppedChar,\n      msg,\n      match\n    const orgText = text\n    const orgLength = orgText.length\n    let offset = 0\n    let matchedTokensIndex = 0\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    const guessedNumberOfTokens = this.hasCustom\n      ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n      : Math.floor(text.length / 10)\n    const matchedTokens = new Array(guessedNumberOfTokens)\n    const errors: ILexingError[] = []\n    let line = this.trackStartLines ? 1 : undefined\n    let column = this.trackStartLines ? 1 : undefined\n    const groups: any = cloneEmptyGroups(this.emptyGroups)\n    const trackLines = this.trackStartLines\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern\n\n    let currModePatternsLength = 0\n    let patternIdxToConfig: IPatternConfig[] = []\n    let currCharCodeToPatternIdxToConfig: {\n      [charCode: number]: IPatternConfig[]\n    } = []\n\n    const modeStack: string[] = []\n\n    const emptyArray: IPatternConfig[] = []\n    Object.freeze(emptyArray)\n    let getPossiblePatterns!: (charCode: number) => IPatternConfig[]\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig\n    }\n\n    function getPossiblePatternsOptimized(charCode: number): IPatternConfig[] {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode)\n      const possiblePatterns =\n        currCharCodeToPatternIdxToConfig[optimizedCharIdx]\n      if (possiblePatterns === undefined) {\n        return emptyArray\n      } else {\n        return possiblePatterns\n      }\n    }\n\n    const pop_mode = (popToken: IToken) => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (\n        modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === undefined\n      ) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg =\n          this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(\n            popToken\n          )\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg\n        })\n      } else {\n        modeStack.pop()\n        const newMode = last(modeStack)!\n        patternIdxToConfig = this.patternIdxToConfig[newMode]\n        currCharCodeToPatternIdxToConfig =\n          this.charCodeToPatternIdxToConfig[newMode]\n        currModePatternsLength = patternIdxToConfig.length\n        const modeCanBeOptimized =\n          this.canModeBeOptimized[newMode] && this.config.safeMode === false\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow\n        }\n      }\n    }\n\n    function push_mode(this: Lexer, newMode: string) {\n      modeStack.push(newMode)\n      currCharCodeToPatternIdxToConfig =\n        this.charCodeToPatternIdxToConfig[newMode]\n\n      patternIdxToConfig = this.patternIdxToConfig[newMode]\n      currModePatternsLength = patternIdxToConfig.length\n\n      currModePatternsLength = patternIdxToConfig.length\n      const modeCanBeOptimized =\n        this.canModeBeOptimized[newMode] && this.config.safeMode === false\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow\n      }\n    }\n\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode)\n\n    let currConfig!: IPatternConfig\n\n    const recoveryEnabled = this.config.recoveryEnabled\n\n    while (offset < orgLength) {\n      matchedImage = null\n\n      const nextCharCode = orgText.charCodeAt(offset)\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode)\n      const chosenPatternsLength = chosenPatternIdxToConfig.length\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i]\n        const currPattern = currConfig.pattern\n        payload = null\n\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        const singleCharCode = currConfig.short\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern as string\n          }\n        } else if (currConfig.isCustom === true) {\n          match = (currPattern as IRegExpExec).exec(\n            orgText,\n            offset,\n            matchedTokens,\n            groups\n          )\n          if (match !== null) {\n            matchedImage = match[0]\n            if ((match as CustomPatternMatcherReturn).payload !== undefined) {\n              payload = (match as CustomPatternMatcherReturn).payload\n            }\n          } else {\n            matchedImage = null\n          }\n        } else {\n          this.updateLastIndex(currPattern as RegExp, offset)\n          matchedImage = this.match(currPattern as RegExp, text, offset)\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]]\n              const longerAltPattern = longerAltConfig.pattern\n              altPayload = null\n\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = (longerAltPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups\n                )\n                if (match !== null) {\n                  matchAltImage = match[0]\n                  if (\n                    (match as CustomPatternMatcherReturn).payload !== undefined\n                  ) {\n                    altPayload = (match as CustomPatternMatcherReturn).payload\n                  }\n                } else {\n                  matchAltImage = null\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern as RegExp, offset)\n                matchAltImage = this.match(\n                  longerAltPattern as RegExp,\n                  text,\n                  offset\n                )\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage\n                payload = altPayload\n                currConfig = longerAltConfig\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break\n              }\n            }\n          }\n          break\n        }\n      }\n\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length\n        group = currConfig.group\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(\n            matchedImage,\n            offset,\n            tokType,\n            currConfig.tokenType,\n            line,\n            column,\n            imageLength\n          )\n\n          this.handlePayload(newToken, payload)\n\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(\n              matchedTokens,\n              matchedTokensIndex,\n              newToken\n            )\n          } else {\n            groups[group].push(newToken)\n          }\n        }\n        text = this.chopInput(text, imageLength)\n        offset = offset + imageLength\n\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column!, imageLength)\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0\n          let foundTerminator\n          let lastLTEndOffset: number\n          lineTerminatorPattern.lastIndex = 0\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage)\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1\n              numOfLTsInMatch++\n            }\n          } while (foundTerminator === true)\n\n          if (numOfLTsInMatch !== 0) {\n            line = line! + numOfLTsInMatch\n            column = imageLength - lastLTEndOffset!\n            this.updateTokenEndLineColumnLocation(\n              newToken!,\n              group!,\n              lastLTEndOffset!,\n              numOfLTsInMatch,\n              line,\n              column,\n              imageLength\n            )\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken!)\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset\n        const errorLine = line\n        const errorColumn = column\n        let foundResyncPoint = recoveryEnabled === false\n\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1)\n          offset++\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j]\n            const currPattern = currConfig.pattern\n\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            const singleCharCode = currConfig.short\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint =\n                (currPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups\n                ) !== null\n            } else {\n              this.updateLastIndex(currPattern as RegExp, offset)\n              foundResyncPoint = (currPattern as RegExp).exec(text) !== null\n            }\n\n            if (foundResyncPoint === true) {\n              break\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(\n          orgText,\n          errorStartOffset,\n          errLength,\n          errorLine,\n          errorColumn\n        )\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        })\n\n        if (recoveryEnabled === false) {\n          break\n        }\n      }\n    }\n\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors\n    }\n  }\n\n  private handleModes(\n    config: IPatternConfig,\n    pop_mode: (tok: IToken) => void,\n    push_mode: (this: Lexer, pushMode: string) => void,\n    newToken: IToken\n  ) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push\n      pop_mode(newToken)\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode)\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push)\n    }\n  }\n\n  private chopInput(text: string, length: number): string {\n    return text.substring(length)\n  }\n\n  private updateLastIndex(regExp: RegExp, newLastIndex: number): void {\n    regExp.lastIndex = newLastIndex\n  }\n\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  private updateTokenEndLineColumnLocation(\n    newToken: IToken,\n    group: string | false,\n    lastLTIdx: number,\n    numOfLTsInMatch: number,\n    line: number,\n    column: number,\n    imageLength: number\n  ): void {\n    let lastCharIsLT, fixForEndingInLT\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1\n      fixForEndingInLT = lastCharIsLT ? -1 : 0\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  }\n\n  private computeNewColumn(oldColumn: number, imageLength: number) {\n    return oldColumn + imageLength\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private createTokenInstance!: (...args: any[]) => IToken\n\n  private createOffsetOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType\n  ) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType\n    }\n  }\n\n  private createStartOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number\n  ) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType\n    }\n  }\n\n  private createFullToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n    imageLength: number\n  ): IToken {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType\n    }\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private addToken!: (\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken\n  ) => number\n\n  private addTokenUsingPush(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken\n  ): number {\n    tokenVector.push(tokenToAdd)\n    return index\n  }\n\n  private addTokenUsingMemberAccess(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken\n  ): number {\n    tokenVector[index] = tokenToAdd\n    index++\n    return index\n  }\n\n  // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n  private handlePayload: (token: IToken, payload: any) => void\n\n  private handlePayloadNoCustom(token: IToken, payload: any): void {}\n\n  private handlePayloadWithCustom(token: IToken, payload: any): void {\n    if (payload !== null) {\n      token.payload = payload\n    }\n  }\n\n  // place holder to be replaced with chosen alternative at runtime\n  private match!: (\n    pattern: RegExp,\n    text: string,\n    offset: number\n  ) => string | null\n\n  private matchWithTest(\n    pattern: RegExp,\n    text: string,\n    offset: number\n  ): string | null {\n    const found = pattern.test(text)\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex)\n    }\n    return null\n  }\n\n  private matchWithExec(pattern: RegExp, text: string): string | null {\n    const regExpArray = pattern.exec(text)\n    return regExpArray !== null ? regExpArray[0] : null\n  }\n\n  // Duplicated from the parser's perf trace trait to allow future extraction\n  // of the lexer to a separate package.\n  TRACE_INIT = <T>(phaseDesc: string, phaseImpl: () => T): T => {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\")\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`)\n      }\n      const { time, value } = timer(phaseImpl)\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`)\n      }\n      this.traceInitIndent--\n      return value\n    } else {\n      return phaseImpl()\n    }\n  }\n}\n"]},"metadata":{},"sourceType":"script","externalDependencies":[]}