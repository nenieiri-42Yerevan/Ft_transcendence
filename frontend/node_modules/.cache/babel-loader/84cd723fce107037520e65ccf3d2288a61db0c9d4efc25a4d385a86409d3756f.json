{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.attemptInRepetitionRecovery = exports.Recoverable = exports.InRuleRecoveryException = exports.IN_RULE_RECOVERY_EXCEPTION = exports.EOF_FOLLOW_KEY = void 0;\nvar tokens_public_1 = require(\"../../../scan/tokens_public\");\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nvar dropRight_1 = __importDefault(require(\"lodash/dropRight\"));\nvar flatten_1 = __importDefault(require(\"lodash/flatten\"));\nvar map_1 = __importDefault(require(\"lodash/map\"));\nvar find_1 = __importDefault(require(\"lodash/find\"));\nvar has_1 = __importDefault(require(\"lodash/has\"));\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\nvar exceptions_public_1 = require(\"../../exceptions_public\");\nvar constants_1 = require(\"../../constants\");\nvar parser_1 = require(\"../parser\");\nexports.EOF_FOLLOW_KEY = {};\nexports.IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nvar InRuleRecoveryException = /** @class */function (_super) {\n  __extends(InRuleRecoveryException, _super);\n  function InRuleRecoveryException(message) {\n    var _this = _super.call(this, message) || this;\n    _this.name = exports.IN_RULE_RECOVERY_EXCEPTION;\n    return _this;\n  }\n  return InRuleRecoveryException;\n}(Error);\nexports.InRuleRecoveryException = InRuleRecoveryException;\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nvar Recoverable = /** @class */function () {\n  function Recoverable() {}\n  Recoverable.prototype.initRecoverable = function (config) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n    this.recoveryEnabled = (0, has_1.default)(config, \"recoveryEnabled\") ? config.recoveryEnabled // assumes end user provides the correct config value/type\n    : parser_1.DEFAULT_PARSER_CONFIG.recoveryEnabled;\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  };\n  Recoverable.prototype.getTokenToInsert = function (tokType) {\n    var tokToInsert = (0, tokens_public_1.createTokenInstance)(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  };\n  Recoverable.prototype.canTokenTypeBeInsertedInRecovery = function (tokType) {\n    return true;\n  };\n  Recoverable.prototype.canTokenTypeBeDeletedInRecovery = function (tokType) {\n    return true;\n  };\n  Recoverable.prototype.tryInRepetitionRecovery = function (grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n    var _this = this;\n    // TODO: can the resyncTokenType be cached?\n    var reSyncTokType = this.findReSyncTokenType();\n    var savedLexerState = this.exportLexerState();\n    var resyncedTokens = [];\n    var passedResyncPoint = false;\n    var nextTokenWithoutResync = this.LA(1);\n    var currToken = this.LA(1);\n    var generateErrorMessage = function () {\n      var previousToken = _this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      var msg = _this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: _this.getCurrRuleFullName()\n      });\n      var error = new exceptions_public_1.MismatchedTokenException(msg, nextTokenWithoutResync, _this.LA(0));\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = (0, dropRight_1.default)(resyncedTokens);\n      _this.SAVE_ERROR(error);\n    };\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  };\n  Recoverable.prototype.shouldInRepetitionRecoveryBeTried = function (expectTokAfterLastMatch, nextTokIdx, notStuck) {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n      return false;\n    }\n    return true;\n  };\n  // Error Recovery functionality\n  Recoverable.prototype.getFollowsForInRuleRecovery = function (tokType, tokIdxInRule) {\n    var grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    var follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  };\n  Recoverable.prototype.tryInRuleRecovery = function (expectedTokType, follows) {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      var tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      var nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  };\n  Recoverable.prototype.canPerformInRuleRecovery = function (expectedToken, follows) {\n    return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n  };\n  Recoverable.prototype.canRecoverWithSingleTokenInsertion = function (expectedTokType, follows) {\n    var _this = this;\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n    // must know the possible following tokens to perform single token insertion\n    if ((0, isEmpty_1.default)(follows)) {\n      return false;\n    }\n    var mismatchedTok = this.LA(1);\n    var isMisMatchedTokInFollows = (0, find_1.default)(follows, function (possibleFollowsTokType) {\n      return _this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n    }) !== undefined;\n    return isMisMatchedTokInFollows;\n  };\n  Recoverable.prototype.canRecoverWithSingleTokenDeletion = function (expectedTokType) {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n    var isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n    return isNextTokenWhatIsExpected;\n  };\n  Recoverable.prototype.isInCurrentRuleReSyncSet = function (tokenTypeIdx) {\n    var followKey = this.getCurrFollowKey();\n    var currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return (0, includes_1.default)(currentRuleReSyncSet, tokenTypeIdx);\n  };\n  Recoverable.prototype.findReSyncTokenType = function () {\n    var allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    var nextToken = this.LA(1);\n    var k = 2;\n    while (true) {\n      var foundMatch = (0, find_1.default)(allPossibleReSyncTokTypes, function (resyncTokType) {\n        var canMatch = (0, tokens_public_1.tokenMatcher)(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  };\n  Recoverable.prototype.getCurrFollowKey = function () {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return exports.EOF_FOLLOW_KEY;\n    }\n    var currRuleShortName = this.getLastExplicitRuleShortName();\n    var currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    var prevRuleShortName = this.getPreviousExplicitRuleShortName();\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    };\n  };\n  Recoverable.prototype.buildFullFollowKeyStack = function () {\n    var _this = this;\n    var explicitRuleStack = this.RULE_STACK;\n    var explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return (0, map_1.default)(explicitRuleStack, function (ruleName, idx) {\n      if (idx === 0) {\n        return exports.EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: _this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: _this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      };\n    });\n  };\n  Recoverable.prototype.flattenFollowSet = function () {\n    var _this = this;\n    var followStack = (0, map_1.default)(this.buildFullFollowKeyStack(), function (currKey) {\n      return _this.getFollowSetFromFollowKey(currKey);\n    });\n    return (0, flatten_1.default)(followStack);\n  };\n  Recoverable.prototype.getFollowSetFromFollowKey = function (followKey) {\n    if (followKey === exports.EOF_FOLLOW_KEY) {\n      return [tokens_public_1.EOF];\n    }\n    var followName = followKey.ruleName + followKey.idxInCallingRule + constants_1.IN + followKey.inRule;\n    return this.resyncFollows[followName];\n  };\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  Recoverable.prototype.addToResyncTokens = function (token, resyncTokens) {\n    if (!this.tokenMatcher(token, tokens_public_1.EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  };\n  Recoverable.prototype.reSyncTo = function (tokType) {\n    var resyncedTokens = [];\n    var nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return (0, dropRight_1.default)(resyncedTokens);\n  };\n  Recoverable.prototype.attemptInRepetitionRecovery = function (prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  };\n  Recoverable.prototype.getCurrentGrammarPath = function (tokType, tokIdxInRule) {\n    var pathRuleStack = this.getHumanReadableRuleStack();\n    var pathOccurrenceStack = (0, clone_1.default)(this.RULE_OCCURRENCE_STACK);\n    var grammarPath = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    };\n    return grammarPath;\n  };\n  Recoverable.prototype.getHumanReadableRuleStack = function () {\n    var _this = this;\n    return (0, map_1.default)(this.RULE_STACK, function (currShortName) {\n      return _this.shortRuleNameToFullName(currShortName);\n    });\n  };\n  return Recoverable;\n}();\nexports.Recoverable = Recoverable;\nfunction attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  var key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  var firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    var currRuleName = this.getCurrRuleFullName();\n    var ruleGrammar = this.getGAstProductions()[currRuleName];\n    var walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n  var expectTokAfterLastMatch = firstAfterRepInfo.token;\n  var nextTokIdx = firstAfterRepInfo.occurrence;\n  var isEndOfRule = firstAfterRepInfo.isEndOfRule;\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === undefined) {\n    expectTokAfterLastMatch = tokens_public_1.EOF;\n    nextTokIdx = 1;\n  }\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n  if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n  }\n}\nexports.attemptInRepetitionRecovery = attemptInRepetitionRecovery;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AAEA;AAEaA,sBAAc,GAAQ,EAAE;AAQxBA,kCAA0B,GAAG,yBAAyB;AAEnE;EAA6CC;EAC3C,iCAAYC,OAAe;IAA3B,YACEC,kBAAMD,OAAO,CAAC;IACdE,KAAI,CAACC,IAAI,GAAGL,kCAA0B;;EACxC;EACF,8BAAC;AAAD,CAAC,CAL4CM,KAAK;AAArCN;AAOb;;;AAGA;EAAA,wBAyWA;EApWEO,qCAAe,GAAf,UAAgBC,MAAqB;IACnC,IAAI,CAACC,gBAAgB,GAAG,EAAE;IAC1B,IAAI,CAACC,aAAa,GAAG,EAAE;IAEvB,IAAI,CAACC,eAAe,GAAG,iBAAG,EAACH,MAAM,EAAE,iBAAiB,CAAC,GAChDA,MAAM,CAACG,eAA2B,CAAC;IAAA,EACpCC,8BAAqB,CAACD,eAAe;IAEzC;IACA;IACA;IACA,IAAI,IAAI,CAACA,eAAe,EAAE;MACxB,IAAI,CAACE,2BAA2B,GAAGA,2BAA2B;;EAElE,CAAC;EAEMN,sCAAgB,GAAvB,UAAwBO,OAAkB;IACxC,IAAMC,WAAW,GAAG,uCAAmB,EACrCD,OAAO,EACP,EAAE,EACFE,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,CACJ;IACDD,WAAW,CAACE,oBAAoB,GAAG,IAAI;IACvC,OAAOF,WAAW;EACpB,CAAC;EAEMR,sDAAgC,GAAvC,UAAwCO,OAAkB;IACxD,OAAO,IAAI;EACb,CAAC;EAEMP,qDAA+B,GAAtC,UAAuCO,OAAkB;IACvD,OAAO,IAAI;EACb,CAAC;EAEDP,6CAAuB,GAAvB,UAEEW,WAAqB,EACrBC,eAAsB,EACtBC,aAA4B,EAC5BC,eAA0B;IAL5B;IAOE;IACA,IAAMC,aAAa,GAAG,IAAI,CAACC,mBAAmB,EAAE;IAChD,IAAMC,eAAe,GAAG,IAAI,CAACC,gBAAgB,EAAE;IAC/C,IAAMC,cAAc,GAAa,EAAE;IACnC,IAAIC,iBAAiB,GAAG,KAAK;IAE7B,IAAMC,sBAAsB,GAAG,IAAI,CAACC,EAAE,CAAC,CAAC,CAAC;IACzC,IAAIC,SAAS,GAAG,IAAI,CAACD,EAAE,CAAC,CAAC,CAAC;IAE1B,IAAME,oBAAoB,GAAG;MAC3B,IAAMC,aAAa,GAAG5B,KAAI,CAACyB,EAAE,CAAC,CAAC,CAAC;MAChC;MACA;MACA,IAAMI,GAAG,GAAG7B,KAAI,CAAC8B,oBAAoB,CAACC,yBAAyB,CAAC;QAC9DC,QAAQ,EAAEf,eAAe;QACzBgB,MAAM,EAAET,sBAAsB;QAC9BU,QAAQ,EAAEN,aAAa;QACvBO,QAAQ,EAAEnC,KAAI,CAACoC,mBAAmB;OACnC,CAAC;MACF,IAAMC,KAAK,GAAG,IAAIC,4CAAwB,CACxCT,GAAG,EACHL,sBAAsB,EACtBxB,KAAI,CAACyB,EAAE,CAAC,CAAC,CAAC,CACX;MACD;MACAY,KAAK,CAACf,cAAc,GAAG,uBAAS,EAACA,cAAc,CAAC;MAChDtB,KAAI,CAACuC,UAAU,CAACF,KAAK,CAAC;IACxB,CAAC;IAED,OAAO,CAACd,iBAAiB,EAAE;MACzB;MACA,IAAI,IAAI,CAACiB,YAAY,CAACd,SAAS,EAAET,eAAe,CAAC,EAAE;QACjDU,oBAAoB,EAAE;QACtB,OAAM,CAAC;OACR,MAAM,IAAIX,aAAa,CAACyB,IAAI,CAAC,IAAI,CAAC,EAAE;QACnC;QACAd,oBAAoB,EAAE;QACtB;QACAb,WAAW,CAAC4B,KAAK,CAAC,IAAI,EAAE3B,eAAe,CAAC;QACxC,OAAM,CAAC;OACR,MAAM,IAAI,IAAI,CAACyB,YAAY,CAACd,SAAS,EAAER,aAAa,CAAC,EAAE;QACtDK,iBAAiB,GAAG,IAAI;OACzB,MAAM;QACLG,SAAS,GAAG,IAAI,CAACiB,UAAU,EAAE;QAC7B,IAAI,CAACC,iBAAiB,CAAClB,SAAS,EAAEJ,cAAc,CAAC;;;IAIrD;IACA;IACA;IACA,IAAI,CAACuB,gBAAgB,CAACzB,eAAe,CAAC;EACxC,CAAC;EAEDjB,uDAAiC,GAAjC,UAEE2C,uBAAkC,EAClCC,UAAkB,EAClBC,QAA6B;IAE7B;IACA;IACA,IAAIA,QAAQ,KAAK,KAAK,EAAE;MACtB,OAAO,KAAK;;IAGd;IACA,IAAI,IAAI,CAACR,YAAY,CAAC,IAAI,CAACf,EAAE,CAAC,CAAC,CAAC,EAAEqB,uBAAuB,CAAC,EAAE;MAC1D,OAAO,KAAK;;IAGd;IACA;IACA,IAAI,IAAI,CAACG,cAAc,EAAE,EAAE;MACzB,OAAO,KAAK;;IAGd;IACA;IACA;IACA,IACE,IAAI,CAACC,wBAAwB,CAC3BJ,uBAAuB,EACvB,IAAI,CAACK,2BAA2B,CAACL,uBAAuB,EAAEC,UAAU,CAAC,CACtE,EACD;MACA,OAAO,KAAK;;IAGd,OAAO,IAAI;EACb,CAAC;EAED;EACA5C,iDAA2B,GAA3B,UAEEO,OAAkB,EAClB0C,YAAoB;IAEpB,IAAMC,WAAW,GAAG,IAAI,CAACC,qBAAqB,CAAC5C,OAAO,EAAE0C,YAAY,CAAC;IACrE,IAAMG,OAAO,GAAG,IAAI,CAACC,yBAAyB,CAACH,WAAW,CAAC;IAC3D,OAAOE,OAAO;EAChB,CAAC;EAEDpD,uCAAiB,GAAjB,UAEEc,eAA0B,EAC1BsC,OAAoB;IAEpB,IAAI,IAAI,CAACE,kCAAkC,CAACxC,eAAe,EAAEsC,OAAO,CAAC,EAAE;MACrE,IAAM5C,WAAW,GAAG,IAAI,CAAC+C,gBAAgB,CAACzC,eAAe,CAAC;MAC1D,OAAON,WAAW;;IAGpB,IAAI,IAAI,CAACgD,iCAAiC,CAAC1C,eAAe,CAAC,EAAE;MAC3D,IAAM2C,OAAO,GAAG,IAAI,CAACjB,UAAU,EAAE;MACjC,IAAI,CAACkB,YAAY,EAAE;MACnB,OAAOD,OAAO;;IAGhB,MAAM,IAAIE,uBAAuB,CAAC,eAAe,CAAC;EACpD,CAAC;EAED3D,8CAAwB,GAAxB,UAEE4D,aAAwB,EACxBR,OAAoB;IAEpB,OACE,IAAI,CAACE,kCAAkC,CAACM,aAAa,EAAER,OAAO,CAAC,IAC/D,IAAI,CAACI,iCAAiC,CAACI,aAAa,CAAC;EAEzD,CAAC;EAED5D,wDAAkC,GAAlC,UAEEc,eAA0B,EAC1BsC,OAAoB;IAHtB;IAKE,IAAI,CAAC,IAAI,CAACS,gCAAgC,CAAC/C,eAAe,CAAC,EAAE;MAC3D,OAAO,KAAK;;IAGd;IACA,IAAI,qBAAO,EAACsC,OAAO,CAAC,EAAE;MACpB,OAAO,KAAK;;IAGd,IAAMU,aAAa,GAAG,IAAI,CAACxC,EAAE,CAAC,CAAC,CAAC;IAChC,IAAMyC,wBAAwB,GAC5B,kBAAI,EAACX,OAAO,EAAE,UAACY,sBAAiC;MAC9C,OAAOnE,KAAI,CAACwC,YAAY,CAACyB,aAAa,EAAEE,sBAAsB,CAAC;IACjE,CAAC,CAAC,KAAKC,SAAS;IAElB,OAAOF,wBAAwB;EACjC,CAAC;EAED/D,uDAAiC,GAAjC,UAEEc,eAA0B;IAE1B,IAAI,CAAC,IAAI,CAACoD,+BAA+B,CAACpD,eAAe,CAAC,EAAE;MAC1D,OAAO,KAAK;;IAGd,IAAMqD,yBAAyB,GAAG,IAAI,CAAC9B,YAAY,CACjD,IAAI,CAACf,EAAE,CAAC,CAAC,CAAC,EACVR,eAAe,CAChB;IACD,OAAOqD,yBAAyB;EAClC,CAAC;EAEDnE,8CAAwB,GAAxB,UAEEoE,YAAuB;IAEvB,IAAMC,SAAS,GAAG,IAAI,CAACC,gBAAgB,EAAE;IACzC,IAAMC,oBAAoB,GAAG,IAAI,CAACC,yBAAyB,CAACH,SAAS,CAAC;IACtE,OAAO,sBAAQ,EAACE,oBAAoB,EAAEH,YAAY,CAAC;EACrD,CAAC;EAEDpE,yCAAmB,GAAnB;IACE,IAAMyE,yBAAyB,GAAG,IAAI,CAACC,gBAAgB,EAAE;IACzD;IACA,IAAIC,SAAS,GAAG,IAAI,CAACrD,EAAE,CAAC,CAAC,CAAC;IAC1B,IAAIsD,CAAC,GAAG,CAAC;IACT,OAAO,IAAI,EAAE;MACX,IAAMC,UAAU,GAAG,kBAAI,EAACJ,yBAAyB,EAAE,UAACK,aAAa;QAC/D,IAAMC,QAAQ,GAAG,gCAAY,EAACJ,SAAS,EAAEG,aAAa,CAAC;QACvD,OAAOC,QAAQ;MACjB,CAAC,CAAC;MACF,IAAIF,UAAU,KAAKZ,SAAS,EAAE;QAC5B,OAAOY,UAAU;;MAEnBF,SAAS,GAAG,IAAI,CAACrD,EAAE,CAACsD,CAAC,CAAC;MACtBA,CAAC,EAAE;;EAEP,CAAC;EAED5E,sCAAgB,GAAhB;IACE;IACA,IAAI,IAAI,CAACgF,UAAU,CAACC,MAAM,KAAK,CAAC,EAAE;MAChC,OAAOxF,sBAAc;;IAEvB,IAAMyF,iBAAiB,GAAG,IAAI,CAACC,4BAA4B,EAAE;IAC7D,IAAMC,WAAW,GAAG,IAAI,CAACC,kCAAkC,EAAE;IAC7D,IAAMC,iBAAiB,GAAG,IAAI,CAACC,gCAAgC,EAAE;IAEjE,OAAO;MACLvD,QAAQ,EAAE,IAAI,CAACwD,uBAAuB,CAACN,iBAAiB,CAAC;MACzDO,gBAAgB,EAAEL,WAAW;MAC7BM,MAAM,EAAE,IAAI,CAACF,uBAAuB,CAACF,iBAAiB;KACvD;EACH,CAAC;EAEDtF,6CAAuB,GAAvB;IAAA;IACE,IAAM2F,iBAAiB,GAAG,IAAI,CAACX,UAAU;IACzC,IAAMY,uBAAuB,GAAG,IAAI,CAACC,qBAAqB;IAE1D,OAAO,iBAAG,EAACF,iBAAiB,EAAE,UAAC3D,QAAQ,EAAE8D,GAAG;MAC1C,IAAIA,GAAG,KAAK,CAAC,EAAE;QACb,OAAOrG,sBAAc;;MAEvB,OAAO;QACLuC,QAAQ,EAAEnC,KAAI,CAAC2F,uBAAuB,CAACxD,QAAQ,CAAC;QAChDyD,gBAAgB,EAAEG,uBAAuB,CAACE,GAAG,CAAC;QAC9CJ,MAAM,EAAE7F,KAAI,CAAC2F,uBAAuB,CAACG,iBAAiB,CAACG,GAAG,GAAG,CAAC,CAAC;OAChE;IACH,CAAC,CAAC;EACJ,CAAC;EAED9F,sCAAgB,GAAhB;IAAA;IACE,IAAM+F,WAAW,GAAG,iBAAG,EAAC,IAAI,CAACC,uBAAuB,EAAE,EAAE,UAACC,OAAO;MAC9D,OAAOpG,KAAI,CAAC2E,yBAAyB,CAACyB,OAAO,CAAC;IAChD,CAAC,CAAC;IACF,OAAY,qBAAO,EAACF,WAAW,CAAC;EAClC,CAAC;EAED/F,+CAAyB,GAAzB,UAEEqE,SAAqB;IAErB,IAAIA,SAAS,KAAK5E,sBAAc,EAAE;MAChC,OAAO,CAACyG,mBAAG,CAAC;;IAGd,IAAMC,UAAU,GACd9B,SAAS,CAACrC,QAAQ,GAAGqC,SAAS,CAACoB,gBAAgB,GAAGW,cAAE,GAAG/B,SAAS,CAACqB,MAAM;IAEzE,OAAO,IAAI,CAACvF,aAAa,CAACgG,UAAU,CAAC;EACvC,CAAC;EAED;EACA;EACAnG,uCAAiB,GAAjB,UAEEqG,KAAa,EACbC,YAAsB;IAEtB,IAAI,CAAC,IAAI,CAACjE,YAAY,CAACgE,KAAK,EAAEH,mBAAG,CAAC,EAAE;MAClCI,YAAY,CAACC,IAAI,CAACF,KAAK,CAAC;;IAE1B,OAAOC,YAAY;EACrB,CAAC;EAEDtG,8BAAQ,GAAR,UAA8BO,OAAkB;IAC9C,IAAMY,cAAc,GAAa,EAAE;IACnC,IAAIsC,OAAO,GAAG,IAAI,CAACnC,EAAE,CAAC,CAAC,CAAC;IACxB,OAAO,IAAI,CAACe,YAAY,CAACoB,OAAO,EAAElD,OAAO,CAAC,KAAK,KAAK,EAAE;MACpDkD,OAAO,GAAG,IAAI,CAACjB,UAAU,EAAE;MAC3B,IAAI,CAACC,iBAAiB,CAACgB,OAAO,EAAEtC,cAAc,CAAC;;IAEjD;IACA,OAAO,uBAAS,EAACA,cAAc,CAAC;EAClC,CAAC;EAEDnB,iDAA2B,GAA3B,UAEEwG,QAAkB,EAClBC,IAAW,EACXC,aAA4B,EAC5BC,YAAoB,EACpBC,cAAsB,EACtBC,cAAgE,EAChEhE,QAAkB;IAElB;IACA;EAAA,CACD;EAED7C,2CAAqB,GAArB,UAEEO,OAAkB,EAClB0C,YAAoB;IAEpB,IAAM6D,aAAa,GAAa,IAAI,CAACC,yBAAyB,EAAE;IAChE,IAAMC,mBAAmB,GAAa,mBAAK,EAAC,IAAI,CAACnB,qBAAqB,CAAC;IACvE,IAAM3C,WAAW,GAAQ;MACvB+D,SAAS,EAAEH,aAAa;MACxBI,eAAe,EAAEF,mBAAmB;MACpCG,OAAO,EAAE5G,OAAO;MAChB6G,iBAAiB,EAAEnE;KACpB;IAED,OAAOC,WAAW;EACpB,CAAC;EACDlD,+CAAyB,GAAzB;IAAA;IACE,OAAO,iBAAG,EAAC,IAAI,CAACgF,UAAU,EAAE,UAACqC,aAAa;MACxC,YAAI,CAAC7B,uBAAuB,CAAC6B,aAAa,CAAC;IAA3C,CAA2C,CAC5C;EACH,CAAC;EACH,kBAAC;AAAD,CAAC,EAzWD;AAAa5H;AA2Wb,SAAgBa,2BAA2B,CAEzCkG,QAAkB,EAClBC,IAAW,EACXC,aAA4B,EAC5BC,YAAoB,EACpBC,cAAsB,EACtBC,cAAgE,EAChEhE,QAAkB;EAElB,IAAMyE,GAAG,GAAG,IAAI,CAACC,2BAA2B,CAACZ,YAAY,EAAEC,cAAc,CAAC;EAC1E,IAAIY,iBAAiB,GAAG,IAAI,CAACtH,gBAAgB,CAACoH,GAAG,CAAC;EAClD,IAAIE,iBAAiB,KAAKvD,SAAS,EAAE;IACnC,IAAMwD,YAAY,GAAG,IAAI,CAACxF,mBAAmB,EAAE;IAC/C,IAAMyF,WAAW,GAAG,IAAI,CAACC,kBAAkB,EAAE,CAACF,YAAY,CAAC;IAC3D,IAAMG,MAAM,GACV,IAAIf,cAAc,CAACa,WAAW,EAAEd,cAAc,CAAC;IACjDY,iBAAiB,GAAGI,MAAM,CAACC,YAAY,EAAE;IACzC,IAAI,CAAC3H,gBAAgB,CAACoH,GAAG,CAAC,GAAGE,iBAAiB;;EAGhD,IAAI7E,uBAAuB,GAAG6E,iBAAiB,CAACnB,KAAK;EACrD,IAAIzD,UAAU,GAAG4E,iBAAiB,CAACM,UAAU;EAC7C,IAAMC,WAAW,GAAGP,iBAAiB,CAACO,WAAW;EAEjD;EACA;EACA,IACE,IAAI,CAAC/C,UAAU,CAACC,MAAM,KAAK,CAAC,IAC5B8C,WAAW,IACXpF,uBAAuB,KAAKsB,SAAS,EACrC;IACAtB,uBAAuB,GAAGuD,mBAAG;IAC7BtD,UAAU,GAAG,CAAC;;EAGhB;EACA;EACA,IAAID,uBAAuB,KAAKsB,SAAS,IAAIrB,UAAU,KAAKqB,SAAS,EAAE;IACrE;;EAGF,IACE,IAAI,CAAC+D,iCAAiC,CACpCrF,uBAAuB,EACvBC,UAAU,EACVC,QAAQ,CACT,EACD;IACA;IACA;IACA;IACA,IAAI,CAACoF,uBAAuB,CAC1BzB,QAAQ,EACRC,IAAI,EACJC,aAAa,EACb/D,uBAAuB,CACxB;;AAEL;AA3DAlD","names":["exports","__extends","message","_super","_this","name","Error","Recoverable","config","firstAfterRepMap","resyncFollows","recoveryEnabled","parser_1","attemptInRepetitionRecovery","tokType","tokToInsert","NaN","isInsertedInRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","resyncedTokens","passedResyncPoint","nextTokenWithoutResync","LA","currToken","generateErrorMessage","previousToken","msg","errorMessageProvider","buildMismatchTokenMessage","expected","actual","previous","ruleName","getCurrRuleFullName","error","exceptions_public_1","SAVE_ERROR","tokenMatcher","call","apply","SKIP_TOKEN","addToResyncTokens","importLexerState","expectTokAfterLastMatch","nextTokIdx","notStuck","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","follows","getNextPossibleTokenTypes","canRecoverWithSingleTokenInsertion","getTokenToInsert","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","InRuleRecoveryException","expectedToken","canTokenTypeBeInsertedInRecovery","mismatchedTok","isMisMatchedTokInFollows","possibleFollowsTokType","undefined","canTokenTypeBeDeletedInRecovery","isNextTokenWhatIsExpected","tokenTypeIdx","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","allPossibleReSyncTokTypes","flattenFollowSet","nextToken","k","foundMatch","resyncTokType","canMatch","RULE_STACK","length","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","idx","followStack","buildFullFollowKeyStack","currKey","tokens_public_1","followName","constants_1","token","resyncTokens","push","prodFunc","args","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","pathRuleStack","getHumanReadableRuleStack","pathOccurrenceStack","ruleStack","occurrenceStack","lastTok","lastTokOccurrence","currShortName","key","getKeyForAutomaticLookahead","firstAfterRepInfo","currRuleName","ruleGrammar","getGAstProductions","walker","startWalking","occurrence","isEndOfRule","shouldInRepetitionRecoveryBeTried","tryInRepetitionRecovery"],"sources":["/Users/tumolabsstudent/Desktop/app/node_modules/chevrotain/src/parse/parser/traits/recoverable.ts"],"sourcesContent":["import {\n  createTokenInstance,\n  EOF,\n  tokenMatcher\n} from \"../../../scan/tokens_public\"\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition\n} from \"../../grammar/interpreter\"\nimport isEmpty from \"lodash/isEmpty\"\nimport dropRight from \"lodash/dropRight\"\nimport flatten from \"lodash/flatten\"\nimport map from \"lodash/map\"\nimport find from \"lodash/find\"\nimport has from \"lodash/has\"\nimport includes from \"lodash/includes\"\nimport clone from \"lodash/clone\"\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType\n} from \"@chevrotain/types\"\nimport { MismatchedTokenException } from \"../../exceptions_public\"\nimport { IN } from \"../../constants\"\nimport { MixedInParser } from \"./parser_traits\"\nimport { DEFAULT_PARSER_CONFIG } from \"../parser\"\n\nexport const EOF_FOLLOW_KEY: any = {}\n\nexport interface IFollowKey {\n  ruleName: string\n  idxInCallingRule: number\n  inRule: string\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\"\n\nexport class InRuleRecoveryException extends Error {\n  constructor(message: string) {\n    super(message)\n    this.name = IN_RULE_RECOVERY_EXCEPTION\n  }\n}\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>\n  resyncFollows: Record<string, TokenType[]>\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {}\n    this.resyncFollows = {}\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN\n    )\n    tokToInsert.isInsertedInRecovery = true\n    return tokToInsert\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\n    return true\n  }\n\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\n    return true\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType()\n    const savedLexerState = this.exportLexerState()\n    const resyncedTokens: IToken[] = []\n    let passedResyncPoint = false\n\n    const nextTokenWithoutResync = this.LA(1)\n    let currToken = this.LA(1)\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0)\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName()\n      })\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0)\n      )\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens)\n      this.SAVE_ERROR(error)\n    }\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage()\n        return // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage()\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs)\n        return // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true\n      } else {\n        currToken = this.SKIP_TOKEN()\n        this.addToResyncTokens(currToken, resyncedTokens)\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState)\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx)\n      )\n    ) {\n      return false\n    }\n\n    return true\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule)\n    const follows = this.getNextPossibleTokenTypes(grammarPath)\n    return follows\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType)\n      return tokToInsert\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN()\n      this.consumeToken()\n      return nextTok\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\")\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    )\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false\n    }\n\n    const mismatchedTok = this.LA(1)\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType)\n      }) !== undefined\n\n    return isMisMatchedTokInFollows\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType\n  ): boolean {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false\n    }\n\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType\n    )\n    return isNextTokenWhatIsExpected\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType\n  ): boolean {\n    const followKey = this.getCurrFollowKey()\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey)\n    return includes(currentRuleReSyncSet, tokenTypeIdx)\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet()\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1)\n    let k = 2\n    while (true) {\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType)\n        return canMatch\n      })\n      if (foundMatch !== undefined) {\n        return foundMatch\n      }\n      nextToken = this.LA(k)\n      k++\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName()\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex()\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName()\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    }\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      }\n    })\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey)\n    })\n    return <any>flatten(followStack)\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF]\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule\n\n    return this.resyncFollows[followName]\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[]\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token)\n    }\n    return resyncTokens\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens: IToken[] = []\n    let nextTok = this.LA(1)\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN()\n      this.addToResyncTokens(nextTok, resyncedTokens)\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens)\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack()\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK)\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    }\n\n    return grammarPath\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName)\n    )\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean\n): void {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence)\n  let firstAfterRepInfo = this.firstAfterRepMap[key]\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName()\n    const ruleGrammar = this.getGAstProductions()[currRuleName]\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence)\n    firstAfterRepInfo = walker.startWalking()\n    this.firstAfterRepMap[key] = firstAfterRepInfo\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token\n  let nextTokIdx = firstAfterRepInfo.occurrence\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF\n    nextTokIdx = 1\n  }\n\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch\n    )\n  }\n}\n"]},"metadata":{},"sourceType":"script","externalDependencies":[]}